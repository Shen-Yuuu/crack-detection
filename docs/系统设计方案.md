# äº‘ç«¯ååŒé“è·¯çŠ¶æ€æ£€æµ‹ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

- **é¡¹ç›®åç§°**: äº‘ç«¯ååŒé“è·¯çŠ¶æ€æ£€æµ‹ç³»ç»Ÿ
- **æŠ€æœ¯æ¶æ„**: Java + Python æ··åˆå¾®æœåŠ¡æ¶æ„
- **æ–‡æ¡£ç‰ˆæœ¬**: v2.0
- **æ›´æ–°æ—¥æœŸ**: 2025-11-06
- **è´Ÿè´£äºº**: é«˜ç»…è¯­
- **æŒ‡å¯¼æ•™å¸ˆ**: æ¨é£

---

## ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#1-ç³»ç»Ÿæ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„è®¾è®¡](#2-ç³»ç»Ÿæ¶æ„è®¾è®¡)
3. [æŠ€æœ¯æ ˆé€‰å‹](#3-æŠ€æœ¯æ ˆé€‰å‹)
4. [æ ¸å¿ƒæ¨¡å—è®¾è®¡](#4-æ ¸å¿ƒæ¨¡å—è®¾è®¡)
5. [æ•°æ®åº“è®¾è®¡](#5-æ•°æ®åº“è®¾è®¡)
6. [æ¥å£è®¾è®¡](#6-æ¥å£è®¾è®¡)
7. [ç³»ç»Ÿäº¤äº’æµç¨‹](#7-ç³»ç»Ÿäº¤äº’æµç¨‹)
8. [éƒ¨ç½²æ–¹æ¡ˆ](#8-éƒ¨ç½²æ–¹æ¡ˆ)
9. [æ€§èƒ½ä¼˜åŒ–](#9-æ€§èƒ½ä¼˜åŒ–)
10. [å®‰å…¨æ–¹æ¡ˆ](#10-å®‰å…¨æ–¹æ¡ˆ)
11. [ç›‘æ§ä¸è¿ç»´](#11-ç›‘æ§ä¸è¿ç»´)
12. [å¼€å‘è®¡åˆ’](#12-å¼€å‘è®¡åˆ’)

---

## 1. ç³»ç»Ÿæ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯

é“è·¯è£‚çº¹æ˜¯é“è·¯æŸåçš„æ—©æœŸè¡¨ç°ï¼ŒåŠæ—¶æ£€æµ‹å’Œä¿®å¤å¯¹äºä¿éšœäº¤é€šå®‰å…¨ã€å»¶é•¿é“è·¯ä½¿ç”¨å¯¿å‘½å…·æœ‰é‡è¦æ„ä¹‰ã€‚ä¼ ç»Ÿçš„äººå·¥å·¡æ£€æ–¹å¼æ•ˆç‡ä½ã€æˆæœ¬é«˜ã€ä¸»è§‚æ€§å¼ºã€‚æœ¬ç³»ç»Ÿåˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯å®ç°é“è·¯è£‚çº¹çš„è‡ªåŠ¨åŒ–æ£€æµ‹ï¼Œç»“åˆäº‘ç«¯ååŒæ¶æ„ï¼Œä¸ºé“è·¯å…»æŠ¤æä¾›æ™ºèƒ½åŒ–ã€ç²¾å‡†åŒ–çš„å†³ç­–æ”¯æŒã€‚

### 1.2 æ ¸å¿ƒç›®æ ‡

| æŒ‡æ ‡ç±»å‹ | å…·ä½“æŒ‡æ ‡ | ç›®æ ‡å€¼ |
|---------|---------|--------|
| **æ£€æµ‹ç²¾åº¦** | å¹³å‡IoU | â‰¥ 85% |
| **æ£€æµ‹ç²¾åº¦** | å°ç›®æ ‡å¬å›ç‡ | â‰¥ 80% |
| **æ£€æµ‹ç²¾åº¦** | ç²¾ç¡®ç‡ | â‰¥ 88% |
| **æ€§èƒ½æŒ‡æ ‡** | å•å¼ å›¾åƒå¤„ç†æ—¶é—´ | â‰¤ 5ç§’ |
| **æ€§èƒ½æŒ‡æ ‡** | æ‰¹é‡å¤„ç†èƒ½åŠ› | â‰¥ 10å¼ /ç§’ |
| **ç³»ç»ŸæŒ‡æ ‡** | å¹¶å‘ç”¨æˆ·æ•° | â‰¥ 100 |
| **ç³»ç»ŸæŒ‡æ ‡** | ç³»ç»Ÿå¯ç”¨æ€§ | â‰¥ 99.5% |

### 1.3 ç³»ç»Ÿç‰¹ç‚¹

ğŸ¯ **æ··åˆæ¶æ„**: Javaå¤„ç†ä¸šåŠ¡é€»è¾‘ï¼ŒPythonå¤„ç†AIæ¨ç†ï¼Œå„å–æ‰€é•¿  
â˜ï¸ **äº‘ç«¯ååŒ**: åˆ†å¸ƒå¼éƒ¨ç½²ï¼Œå¼¹æ€§æ‰©å±•ï¼Œè´Ÿè½½å‡è¡¡  
ğŸ”’ **å®‰å…¨å¯é **: JWTè®¤è¯ï¼Œæ•°æ®åŠ å¯†ï¼Œæƒé™æ§åˆ¶  
ğŸ“Š **å¯è§†åŒ–**: äº¤äº’å¼ç•Œé¢ï¼Œå¤šå›¾å±‚å±•ç¤ºï¼Œè‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ  
ğŸš€ **é«˜æ€§èƒ½**: å¼‚æ­¥å¤„ç†ï¼Œç¼“å­˜ä¼˜åŒ–ï¼Œæ‰¹é‡æ¨ç†  
ğŸ“¦ **æ˜“éƒ¨ç½²**: Dockerå®¹å™¨åŒ–ï¼ŒKubernetesç¼–æ’  

---

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ€»ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ç”¨æˆ·å±‚ (User Layer)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Webæµè§ˆå™¨   â”‚  â”‚  ç§»åŠ¨ç«¯APP   â”‚  â”‚   ç®¡ç†åå°    â”‚                   â”‚
â”‚  â”‚   (Vue 3)    â”‚  â”‚  (Flutter)   â”‚  â”‚   (Vue 3)    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“ HTTPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ¥å…¥å±‚ (Gateway Layer)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Spring Cloud Gateway (Nginxå¤‡é€‰)                        â”‚   â”‚
â”‚  â”‚  â€¢ è·¯ç”±è½¬å‘  â€¢ è´Ÿè½½å‡è¡¡  â€¢ é™æµç†”æ–­  â€¢ è®¤è¯é‰´æƒ  â€¢ æ—¥å¿—è¿½è¸ª      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ä¸šåŠ¡æœåŠ¡å±‚ (Business Service Layer)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  è®¤è¯æœåŠ¡       â”‚  â”‚  æ•°æ®é›†æœåŠ¡     â”‚  â”‚  æ¨ç†æœåŠ¡       â”‚            â”‚
â”‚  â”‚  cloud-auth    â”‚  â”‚  cloud-dataset â”‚  â”‚  cloud-inferenceâ”‚            â”‚
â”‚  â”‚  Spring Boot   â”‚  â”‚  Spring Boot   â”‚  â”‚  Spring Boot   â”‚            â”‚
â”‚  â”‚  â€¢ ç”¨æˆ·ç®¡ç†     â”‚  â”‚  â€¢ æ•°æ®å¯¼å…¥     â”‚  â”‚  â€¢ ä»»åŠ¡ç®¡ç†     â”‚            â”‚
â”‚  â”‚  â€¢ JWTè®¤è¯     â”‚  â”‚  â€¢ æ ¼å¼è½¬æ¢     â”‚  â”‚  â€¢ ç»“æœå¤„ç†     â”‚            â”‚
â”‚  â”‚  â€¢ æƒé™æ§åˆ¶     â”‚  â”‚  â€¢ æ•°æ®å¢å¼º     â”‚  â”‚  â€¢ æ‰¹é‡æ¨ç†     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  å¯è§†åŒ–æœåŠ¡     â”‚  â”‚  æŠ¥å‘ŠæœåŠ¡       â”‚  â”‚  ä»»åŠ¡è°ƒåº¦æœåŠ¡   â”‚            â”‚
â”‚  â”‚  cloud-visual  â”‚  â”‚  cloud-report  â”‚  â”‚  cloud-task    â”‚            â”‚
â”‚  â”‚  Spring Boot   â”‚  â”‚  Spring Boot   â”‚  â”‚  XXL-Job       â”‚            â”‚
â”‚  â”‚  â€¢ å›¾åƒå åŠ      â”‚  â”‚  â€¢ PDFç”Ÿæˆ     â”‚  â”‚  â€¢ å®šæ—¶ä»»åŠ¡     â”‚            â”‚
â”‚  â”‚  â€¢ çƒ­åŠ›å›¾       â”‚  â”‚  â€¢ Excelå¯¼å‡º   â”‚  â”‚  â€¢ å¼‚æ­¥å¤„ç†     â”‚            â”‚
â”‚  â”‚  â€¢ ç»Ÿè®¡åˆ†æ     â”‚  â”‚  â€¢ æŠ¥å‘Šæ¨¡æ¿     â”‚  â”‚  â€¢ æ¶ˆæ¯æ¶ˆè´¹     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“ HTTP/gRPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AIæ¨ç†å±‚ (AI Inference Layer)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚               Pythonæ¨ç†æœåŠ¡ (FastAPI + PyTorch)                  â”‚   â”‚
â”‚  â”‚  â€¢ æ¨¡å‹åŠ è½½  â€¢ å›¾åƒé¢„å¤„ç†  â€¢ æ¨¡å‹æ¨ç†  â€¢ åå¤„ç†  â€¢ ç‰¹å¾æå–       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  U-Netæ¨¡å‹   â”‚  â”‚  DeepLabV3+  â”‚  â”‚  è‡ªå®šä¹‰æ¨¡å‹   â”‚                 â”‚
â”‚  â”‚  (åŸºç¡€ç‰ˆæœ¬)  â”‚  â”‚  (é«˜ç²¾åº¦ç‰ˆ)  â”‚  â”‚  (è¾¹ç¼˜æ£€æµ‹)   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                         GPUè®¡ç®—èŠ‚ç‚¹æ±                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®å­˜å‚¨å±‚ (Data Storage Layer)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ PostgreSQL â”‚  â”‚   Redis    â”‚  â”‚   MinIO    â”‚  â”‚  RabbitMQ  â”‚       â”‚
â”‚  â”‚ (ä¸»æ•°æ®åº“) â”‚  â”‚  (ç¼“å­˜)    â”‚  â”‚ (å¯¹è±¡å­˜å‚¨) â”‚  â”‚ (æ¶ˆæ¯é˜Ÿåˆ—) â”‚       â”‚
â”‚  â”‚ â€¢ ä¸šåŠ¡æ•°æ®  â”‚  â”‚ â€¢ ä¼šè¯     â”‚  â”‚ â€¢ å›¾åƒ     â”‚  â”‚ â€¢ å¼‚æ­¥ä»»åŠ¡  â”‚       â”‚
â”‚  â”‚ â€¢ å…ƒæ•°æ®    â”‚  â”‚ â€¢ çƒ­æ•°æ®   â”‚  â”‚ â€¢ æ¨¡å‹     â”‚  â”‚ â€¢ äº‹ä»¶æ€»çº¿  â”‚       â”‚
â”‚  â”‚ â€¢ ç”¨æˆ·ä¿¡æ¯  â”‚  â”‚ â€¢ åˆ†å¸ƒå¼é” â”‚  â”‚ â€¢ ç»“æœ     â”‚  â”‚ â€¢ æ—¥å¿—é˜Ÿåˆ—  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚Elasticsearchâ”‚  â”‚  MongoDB   â”‚                                         â”‚
â”‚  â”‚ (æ—¥å¿—æœç´¢) â”‚  â”‚(æ–‡æ¡£å­˜å‚¨)  â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç›‘æ§è¿ç»´å±‚ (Monitoring & Ops Layer)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Prometheus â”‚  â”‚  Grafana   â”‚  â”‚    ELK     â”‚  â”‚   Jaeger   â”‚       â”‚
â”‚  â”‚ (æŒ‡æ ‡é‡‡é›†) â”‚  â”‚ (å¯è§†åŒ–)   â”‚  â”‚ (æ—¥å¿—åˆ†æ) â”‚  â”‚ (é“¾è·¯è¿½è¸ª) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å¾®æœåŠ¡æ‹†åˆ†ç­–ç•¥

#### 2.2.1 æœåŠ¡åˆ’åˆ†åŸåˆ™

- **ä¸šåŠ¡è¾¹ç•Œæ¸…æ™°**: æŒ‰ç…§ä¸šåŠ¡é¢†åŸŸè¿›è¡Œæ‹†åˆ†
- **é«˜å†…èšä½è€¦åˆ**: æœåŠ¡å†…éƒ¨åŠŸèƒ½å†…èšï¼ŒæœåŠ¡é—´æ¾è€¦åˆ
- **ç‹¬ç«‹éƒ¨ç½²**: æ¯ä¸ªæœåŠ¡å¯ä»¥ç‹¬ç«‹å¼€å‘ã€æµ‹è¯•ã€éƒ¨ç½²
- **æŠ€æœ¯å¼‚æ„**: Javaå’ŒPythonå„å¸å…¶èŒ

#### 2.2.2 æœåŠ¡æ¸…å•

| æœåŠ¡åç§° | æŠ€æœ¯æ ˆ | ç«¯å£ | èŒè´£ | ä¾èµ–æœåŠ¡ |
|---------|--------|------|------|---------|
| **cloud-gateway** | Spring Cloud Gateway | 8080 | APIç½‘å…³ã€è·¯ç”±è½¬å‘ã€è®¤è¯ | Redis |
| **cloud-auth** | Spring Boot + Security | 8081 | ç”¨æˆ·è®¤è¯ã€æƒé™ç®¡ç† | PostgreSQL, Redis |
| **cloud-dataset** | Spring Boot + MyBatis Plus | 8082 | æ•°æ®é›†ç®¡ç†ã€é¢„å¤„ç† | PostgreSQL, MinIO, RabbitMQ |
| **cloud-inference** | Spring Boot + Feign | 8083 | æ¨ç†ä»»åŠ¡ç®¡ç†ã€ç»“æœå¤„ç† | PostgreSQL, Redis, Pythonæ¨ç†æœåŠ¡ |
| **cloud-visual** | Spring Boot | 8084 | å›¾åƒå¯è§†åŒ–ã€å åŠ ç”Ÿæˆ | PostgreSQL, MinIO |
| **cloud-report** | Spring Boot + iText | 8085 | æŠ¥å‘Šç”Ÿæˆã€æ•°æ®å¯¼å‡º | PostgreSQL, MinIO |
| **cloud-task** | XXL-Job | 8086 | å®šæ—¶ä»»åŠ¡ã€å¼‚æ­¥ä»»åŠ¡ | RabbitMQ, Redis |
| **python-inference** | FastAPI + PyTorch | 8090 | æ¨¡å‹æ¨ç†ã€å›¾åƒå¤„ç† | MinIO, Redis |

### 2.3 æœåŠ¡é—´é€šä¿¡æ–¹å¼

#### 2.3.1 åŒæ­¥é€šä¿¡

```java
// ä½¿ç”¨OpenFeignè¿›è¡ŒæœåŠ¡é—´è°ƒç”¨
@FeignClient(name = "python-inference", url = "${python.inference.url}")
public interface PythonInferenceClient {
    @PostMapping("/api/v1/inference/detect")
    DetectionResult detect(@RequestBody DetectionRequest request);
}
```

**é€‚ç”¨åœºæ™¯**:
- JavaæœåŠ¡è°ƒç”¨Pythonæ¨ç†æœåŠ¡
- éœ€è¦ç«‹å³è·å–ç»“æœçš„åœºæ™¯
- å®æ—¶æ€§è¦æ±‚é«˜çš„ä¸šåŠ¡

#### 2.3.2 å¼‚æ­¥é€šä¿¡

```java
// ä½¿ç”¨RabbitMQè¿›è¡Œå¼‚æ­¥é€šä¿¡
@Component
public class InferenceTaskProducer {
    @Autowired
    private RabbitTemplate rabbitTemplate;
    
    public void sendInferenceTask(InferenceTask task) {
        rabbitTemplate.convertAndSend(
            "inference.exchange", 
            "inference.task", 
            task
        );
    }
}
```

**é€‚ç”¨åœºæ™¯**:
- æ‰¹é‡å¤„ç†ä»»åŠ¡
- ä¸éœ€è¦ç«‹å³è¿”å›ç»“æœ
- å‰Šå³°å¡«è°·åœºæ™¯

### 2.4 æ•°æ®æµè½¬æ¶æ„

```
ç”¨æˆ·ä¸Šä¼ å›¾åƒ
     â†“
API Gateway (éªŒè¯ã€é™æµ)
     â†“
cloud-dataset (ä¿å­˜åˆ°MinIOï¼Œå…ƒæ•°æ®å…¥åº“)
     â†“
cloud-inference (åˆ›å»ºæ¨ç†ä»»åŠ¡)
     â†“
RabbitMQ (ä»»åŠ¡é˜Ÿåˆ—)
     â†“
python-inference (æ¨¡å‹æ¨ç†)
     â†“
cloud-inference (ç»“æœå¤„ç†ã€å…¥åº“)
     â†“
cloud-visual (ç”Ÿæˆå¯è§†åŒ–ç»“æœ)
     â†“
MinIO (ä¿å­˜ç»“æœå›¾åƒ)
     â†“
ç”¨æˆ·æŸ¥çœ‹ç»“æœ
```

---

## 3. æŠ€æœ¯æ ˆé€‰å‹

### 3.1 åç«¯æŠ€æœ¯æ ˆï¼ˆJavaï¼‰

#### 3.1.1 æ ¸å¿ƒæ¡†æ¶

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **JDK** | 17 LTS | Javaè¿è¡Œç¯å¢ƒ | é•¿æœŸæ”¯æŒç‰ˆæœ¬ï¼Œæ€§èƒ½ä¼˜åŒ– |
| **Spring Boot** | 3.2.0 | å¾®æœåŠ¡æ¡†æ¶ | ç®€åŒ–é…ç½®ï¼Œå¿«é€Ÿå¼€å‘ï¼Œç”Ÿæ€å®Œå–„ |
| **Spring Cloud** | 2023.0.0 | å¾®æœåŠ¡æ²»ç† | æœåŠ¡æ³¨å†Œã€é…ç½®ç®¡ç†ã€ç†”æ–­é™çº§ |
| **Spring Cloud Gateway** | 4.1.0 | APIç½‘å…³ | å“åº”å¼æ¶æ„ï¼Œæ€§èƒ½ä¼˜å¼‚ |
| **Spring Security** | 6.2.0 | å®‰å…¨æ¡†æ¶ | è®¤è¯æˆæƒã€é˜²æŠ¤æœºåˆ¶å®Œå–„ |
| **MyBatis Plus** | 3.5.5 | ORMæ¡†æ¶ | ç®€åŒ–CRUDï¼Œä»£ç ç”Ÿæˆå™¨ |

#### 3.1.2 æœåŠ¡æ²»ç†

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **Nacos** | 2.3.0 | æœåŠ¡æ³¨å†Œä¸é…ç½® | é˜¿é‡Œå¼€æºï¼ŒåŠŸèƒ½å…¨é¢ï¼Œç¤¾åŒºæ´»è·ƒ |
| **Sentinel** | 1.8.6 | æµé‡æ§åˆ¶ä¸ç†”æ–­ | è½»é‡çº§ï¼Œè§„åˆ™åŠ¨æ€é…ç½® |
| **Seata** | 1.7.0 | åˆ†å¸ƒå¼äº‹åŠ¡ | å¤šç§äº‹åŠ¡æ¨¡å¼ï¼Œæ€§èƒ½å¥½ |
| **OpenFeign** | 4.1.0 | å£°æ˜å¼HTTPå®¢æˆ·ç«¯ | ç®€åŒ–æœåŠ¡è°ƒç”¨ï¼Œé›†æˆè´Ÿè½½å‡è¡¡ |

#### 3.1.3 æ•°æ®è®¿é—®

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **PostgreSQL** | 15.5 | å…³ç³»æ•°æ®åº“ | åŠŸèƒ½å¼ºå¤§ï¼Œæ”¯æŒJSONï¼ŒGISæ‰©å±• |
| **Redis** | 7.2 | ç¼“å­˜ | é«˜æ€§èƒ½ï¼Œä¸°å¯Œçš„æ•°æ®ç»“æ„ |
| **Redisson** | 3.25.2 | Rediså®¢æˆ·ç«¯ | åˆ†å¸ƒå¼é”ï¼Œå¯¹è±¡æ˜ å°„ |
| **Druid** | 1.2.20 | æ•°æ®åº“è¿æ¥æ±  | ç›‘æ§åŠŸèƒ½å¼ºå¤§ï¼ŒSQLé˜²æ³¨å…¥ |
| **MinIO** | 8.5.7 | å¯¹è±¡å­˜å‚¨ | S3å…¼å®¹ï¼Œç§æœ‰åŒ–éƒ¨ç½² |

#### 3.1.4 æ¶ˆæ¯é˜Ÿåˆ—

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **RabbitMQ** | 3.12.10 | æ¶ˆæ¯é˜Ÿåˆ— | å¯é æ€§é«˜ï¼Œç®¡ç†ç•Œé¢å‹å¥½ |
| **Spring AMQP** | 3.1.0 | AMQPåè®® | Springå®˜æ–¹æ”¯æŒ |

#### 3.1.5 ä»»åŠ¡è°ƒåº¦

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **XXL-Job** | 2.4.0 | åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ | è½»é‡çº§ï¼Œæ˜“äºä½¿ç”¨ |
| **Spring Task** | 6.1.0 | ç®€å•å®šæ—¶ä»»åŠ¡ | Springå†…ç½® |

### 3.2 AIæ¨ç†æŠ€æœ¯æ ˆï¼ˆPythonï¼‰

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **Python** | 3.10+ | ç¼–ç¨‹è¯­è¨€ | AIç”Ÿæ€æœ€å®Œå–„ |
| **FastAPI** | 0.108.0 | Webæ¡†æ¶ | é«˜æ€§èƒ½ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ |
| **PyTorch** | 2.1.0 | æ·±åº¦å­¦ä¹ æ¡†æ¶ | çµæ´»ï¼Œç¤¾åŒºæ´»è·ƒ |
| **TorchServe** | 0.9.0 | æ¨¡å‹æœåŠ¡åŒ– | å®˜æ–¹æ¨ç†æœåŠ¡å™¨ |
| **OpenCV** | 4.8.0 | å›¾åƒå¤„ç† | åŠŸèƒ½å…¨é¢ï¼Œæ€§èƒ½ä¼˜å¼‚ |
| **Pillow** | 10.1.0 | å›¾åƒå¤„ç† | ç®€å•æ˜“ç”¨ |
| **Albumentations** | 1.3.1 | æ•°æ®å¢å¼º | å¢å¼ºæ–¹æ³•ä¸°å¯Œ |
| **scikit-image** | 0.22.0 | å›¾åƒå¤„ç† | ç§‘å­¦è®¡ç®— |

### 3.3 å‰ç«¯æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **Vue** | 3.3.0 | å‰ç«¯æ¡†æ¶ | å“åº”å¼ï¼Œç»„ä»¶åŒ– |
| **TypeScript** | 5.3.0 | ç±»å‹ç³»ç»Ÿ | ç±»å‹å®‰å…¨ï¼Œæé«˜ä»£ç è´¨é‡ |
| **Vite** | 5.0.0 | æ„å»ºå·¥å…· | å¿«é€Ÿçƒ­æ›´æ–° |
| **Element Plus** | 2.4.0 | UIç»„ä»¶åº“ | ç»„ä»¶ä¸°å¯Œï¼Œæ–‡æ¡£å®Œå–„ |
| **ECharts** | 5.4.0 | æ•°æ®å¯è§†åŒ– | å›¾è¡¨ç±»å‹ä¸°å¯Œ |
| **Fabric.js** | 5.3.0 | Canvasæ“ä½œ | å›¾åƒæ ‡æ³¨ |
| **Pinia** | 2.1.0 | çŠ¶æ€ç®¡ç† | Vue3å®˜æ–¹æ¨è |
| **Axios** | 1.6.0 | HTTPå®¢æˆ·ç«¯ | Promise API |

### 3.4 DevOpsæŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **Docker** | 24.0+ | å®¹å™¨åŒ– | æ ‡å‡†å®¹å™¨æŠ€æœ¯ |
| **Kubernetes** | 1.28+ | å®¹å™¨ç¼–æ’ | ç”Ÿäº§çº§ç¼–æ’å·¥å…· |
| **Jenkins** | 2.426+ | CI/CD | æ’ä»¶ä¸°å¯Œï¼Œçµæ´» |
| **GitLab CI** | 16.6+ | CI/CD | ä¸Gité›†æˆå¥½ |
| **Harbor** | 2.9+ | é•œåƒä»“åº“ | ç§æœ‰ä»“åº“ï¼Œå®‰å…¨ |

### 3.5 ç›‘æ§æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|----------|
| **Prometheus** | 2.48+ | æŒ‡æ ‡é‡‡é›† | æ—¶åºæ•°æ®åº“ï¼Œå¼ºå¤§çš„æŸ¥è¯¢ |
| **Grafana** | 10.2+ | å¯è§†åŒ– | ä¸°å¯Œçš„å›¾è¡¨å’Œé¢æ¿ |
| **Elasticsearch** | 8.11+ | æ—¥å¿—å­˜å‚¨ä¸æœç´¢ | å…¨æ–‡æœç´¢å¼ºå¤§ |
| **Logstash** | 8.11+ | æ—¥å¿—æ”¶é›† | æ•°æ®ç®¡é“ |
| **Kibana** | 8.11+ | æ—¥å¿—å¯è§†åŒ– | ELKå¥—ä»¶ |
| **Jaeger** | 1.51+ | é“¾è·¯è¿½è¸ª | åˆ†å¸ƒå¼è¿½è¸ª |
| **SkyWalking** | 9.6+ | APMç›‘æ§ | å›½äº§ï¼Œå¯¹Javaå‹å¥½ |

---

## 4. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 4.1 è®¤è¯æœåŠ¡ (cloud-auth)

#### 4.1.1 åŠŸèƒ½è®¾è®¡

**æ ¸å¿ƒåŠŸèƒ½**:
- ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€ç™»å‡º
- JWTä»¤ç‰Œç”Ÿæˆä¸éªŒè¯
- æƒé™ç®¡ç†ï¼ˆRBACï¼‰
- ç¬¬ä¸‰æ–¹ç™»å½•ï¼ˆGitHubã€Googleï¼‰
- å¯†ç åŠ å¯†ä¸é‡ç½®

**æŠ€æœ¯å®ç°**:
```java
@Service
@RequiredArgsConstructor
public class AuthService {
    
    private final UserMapper userMapper;
    private final RedisTemplate<String, String> redisTemplate;
    private final PasswordEncoder passwordEncoder;
    private final JwtTokenProvider jwtTokenProvider;
    
    /**
     * ç”¨æˆ·ç™»å½•
     */
    public LoginResponse login(LoginRequest request) {
        // 1. éªŒè¯ç”¨æˆ·åå¯†ç 
        User user = userMapper.selectOne(
            new LambdaQueryWrapper<User>()
                .eq(User::getUsername, request.getUsername())
        );
        
        if (user == null || !passwordEncoder.matches(
                request.getPassword(), user.getPassword())) {
            throw new BadCredentialsException("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯");
        }
        
        // 2. ç”ŸæˆJWTä»¤ç‰Œ
        String accessToken = jwtTokenProvider.generateAccessToken(user);
        String refreshToken = jwtTokenProvider.generateRefreshToken(user);
        
        // 3. ç¼“å­˜åˆ°Redis
        String key = "user:token:" + user.getId();
        redisTemplate.opsForValue().set(key, accessToken, 7, TimeUnit.DAYS);
        
        // 4. è®°å½•ç™»å½•æ—¥å¿—
        saveLoginLog(user.getId(), request.getIpAddress());
        
        return LoginResponse.builder()
            .accessToken(accessToken)
            .refreshToken(refreshToken)
            .expiresIn(3600)
            .tokenType("Bearer")
            .userInfo(convertToUserInfo(user))
            .build();
    }
    
    /**
     * åˆ·æ–°ä»¤ç‰Œ
     */
    public LoginResponse refreshToken(String refreshToken) {
        if (!jwtTokenProvider.validateToken(refreshToken)) {
            throw new TokenExpiredException("åˆ·æ–°ä»¤ç‰Œå·²è¿‡æœŸ");
        }
        
        Long userId = jwtTokenProvider.getUserIdFromToken(refreshToken);
        User user = userMapper.selectById(userId);
        
        String newAccessToken = jwtTokenProvider.generateAccessToken(user);
        
        return LoginResponse.builder()
            .accessToken(newAccessToken)
            .expiresIn(3600)
            .tokenType("Bearer")
            .build();
    }
    
    /**
     * ç™»å‡º
     */
    public void logout(Long userId) {
        String key = "user:token:" + userId;
        redisTemplate.delete(key);
    }
}
```

#### 4.1.2 æƒé™æ¨¡å‹ï¼ˆRBACï¼‰

```java
/**
 * ç”¨æˆ·-è§’è‰²-æƒé™æ¨¡å‹
 */

// ç”¨æˆ·è¡¨
@Data
@TableName("sys_user")
public class User {
    private Long id;
    private String username;
    private String password;
    private String email;
    private String phone;
    private Integer status; // 0-ç¦ç”¨ 1-å¯ç”¨
    private LocalDateTime createdAt;
}

// è§’è‰²è¡¨
@Data
@TableName("sys_role")
public class Role {
    private Long id;
    private String roleName;
    private String roleCode;
    private String description;
    private Integer status;
}

// æƒé™è¡¨
@Data
@TableName("sys_permission")
public class Permission {
    private Long id;
    private String permissionName;
    private String permissionCode;
    private String resourceType; // menu, button, api
    private String resourcePath;
    private String method; // GET, POST, PUT, DELETE
}

// ç”¨æˆ·-è§’è‰²å…³è”è¡¨
@Data
@TableName("sys_user_role")
public class UserRole {
    private Long userId;
    private Long roleId;
}

// è§’è‰²-æƒé™å…³è”è¡¨
@Data
@TableName("sys_role_permission")
public class RolePermission {
    private Long roleId;
    private Long permissionId;
}
```

#### 4.1.3 JWTå·¥å…·ç±»

```java
@Component
@ConfigurationProperties(prefix = "jwt")
@Data
public class JwtTokenProvider {
    
    private String secretKey;
    private long accessTokenValidityInSeconds = 3600; // 1å°æ—¶
    private long refreshTokenValidityInSeconds = 604800; // 7å¤©
    
    /**
     * ç”Ÿæˆè®¿é—®ä»¤ç‰Œ
     */
    public String generateAccessToken(User user) {
        Map<String, Object> claims = new HashMap<>();
        claims.put("userId", user.getId());
        claims.put("username", user.getUsername());
        claims.put("roles", getUserRoles(user.getId()));
        
        return Jwts.builder()
            .setClaims(claims)
            .setSubject(user.getUsername())
            .setIssuedAt(new Date())
            .setExpiration(new Date(System.currentTimeMillis() + 
                accessTokenValidityInSeconds * 1000))
            .signWith(SignatureAlgorithm.HS512, secretKey)
            .compact();
    }
    
    /**
     * éªŒè¯ä»¤ç‰Œ
     */
    public boolean validateToken(String token) {
        try {
            Jwts.parser().setSigningKey(secretKey).parseClaimsJws(token);
            return true;
        } catch (JwtException | IllegalArgumentException e) {
            return false;
        }
    }
    
    /**
     * ä»ä»¤ç‰Œä¸­è·å–ç”¨æˆ·ID
     */
    public Long getUserIdFromToken(String token) {
        Claims claims = Jwts.parser()
            .setSigningKey(secretKey)
            .parseClaimsJws(token)
            .getBody();
        return Long.valueOf(claims.get("userId").toString());
    }
}
```

### 4.2 æ•°æ®é›†ç®¡ç†æœåŠ¡ (cloud-dataset)

#### 4.2.1 æ•°æ®é›†å¯¼å…¥æµç¨‹

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class DatasetImportService {
    
    private final MinioService minioService;
    private final DatasetMapper datasetMapper;
    private final ImageMapper imageMapper;
    private final RabbitTemplate rabbitTemplate;
    
    /**
     * å¯¼å…¥æ•°æ®é›†
     */
    @Transactional(rollbackFor = Exception.class)
    public DatasetImportResult importDataset(DatasetImportRequest request) {
        log.info("å¼€å§‹å¯¼å…¥æ•°æ®é›†: {}", request.getName());
        
        // 1. åˆ›å»ºæ•°æ®é›†è®°å½•
        Dataset dataset = createDatasetRecord(request);
        
        // 2. æ ¹æ®æ¥æºä¸‹è½½æ•°æ®
        String localPath = downloadDataset(request);
        
        // 3. è§£ææ•°æ®é›†
        List<ImageInfo> images = parseDataset(localPath, request.getFormat());
        
        // 4. ä¸Šä¼ åˆ°MinIO
        String storagePath = uploadToMinio(dataset.getId(), localPath);
        dataset.setStoragePath(storagePath);
        
        // 5. ä¿å­˜å›¾åƒå…ƒæ•°æ®
        saveImageMetadata(dataset.getId(), images);
        
        // 6. å‘é€é¢„å¤„ç†ä»»åŠ¡åˆ°é˜Ÿåˆ—
        if (request.isAutoPreprocess()) {
            sendPreprocessTask(dataset.getId(), request.getPreprocessConfig());
        }
        
        // 7. æ›´æ–°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        updateDatasetStatistics(dataset);
        
        log.info("æ•°æ®é›†å¯¼å…¥å®Œæˆ: {}", dataset.getId());
        
        return DatasetImportResult.builder()
            .datasetId(dataset.getId())
            .totalImages(images.size())
            .status("success")
            .build();
    }
    
    /**
     * è§£ææ•°æ®é›†ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
     */
    private List<ImageInfo> parseDataset(String path, DatasetFormat format) {
        switch (format) {
            case COCO:
                return new CocoFormatParser().parse(path);
            case PASCAL_VOC:
                return new VocFormatParser().parse(path);
            case YOLO:
                return new YoloFormatParser().parse(path);
            case CUSTOM:
                return new CustomFormatParser().parse(path);
            default:
                throw new UnsupportedOperationException("ä¸æ”¯æŒçš„æ ¼å¼: " + format);
        }
    }
    
    /**
     * ä¸Šä¼ åˆ°MinIO
     */
    private String uploadToMinio(Long datasetId, String localPath) {
        String bucketName = "crack-detection-datasets";
        String objectPrefix = "dataset-" + datasetId + "/";
        
        File directory = new File(localPath);
        File[] files = directory.listFiles();
        
        for (File file : files) {
            if (file.isFile()) {
                String objectName = objectPrefix + file.getName();
                minioService.uploadFile(file, bucketName, objectName);
            }
        }
        
        return bucketName + "/" + objectPrefix;
    }
    
    /**
     * å‘é€é¢„å¤„ç†ä»»åŠ¡
     */
    private void sendPreprocessTask(Long datasetId, PreprocessConfig config) {
        PreprocessTask task = PreprocessTask.builder()
            .datasetId(datasetId)
            .config(config)
            .taskId(UUID.randomUUID().toString())
            .build();
        
        rabbitTemplate.convertAndSend(
            "preprocessing.exchange",
            "preprocessing.dataset",
            task
        );
    }
}
```

#### 4.2.2 æ•°æ®é¢„å¤„ç†

```java
@Service
@RequiredArgsConstructor
public class DataPreprocessService {
    
    /**
     * æ•°æ®é›†åˆ’åˆ†
     */
    public SplitResult splitDataset(Long datasetId, double[] ratio) {
        // ratio: [train, val, test] = [0.7, 0.15, 0.15]
        
        List<Image> images = imageMapper.selectList(
            new LambdaQueryWrapper<Image>()
                .eq(Image::getDatasetId, datasetId)
        );
        
        // æ‰“ä¹±é¡ºåº
        Collections.shuffle(images);
        
        int total = images.size();
        int trainSize = (int) (total * ratio[0]);
        int valSize = (int) (total * ratio[1]);
        
        // åˆ†é…splitæ ‡ç­¾
        for (int i = 0; i < total; i++) {
            Image image = images.get(i);
            if (i < trainSize) {
                image.setSplit("train");
            } else if (i < trainSize + valSize) {
                image.setSplit("val");
            } else {
                image.setSplit("test");
            }
            imageMapper.updateById(image);
        }
        
        return SplitResult.builder()
            .trainCount(trainSize)
            .valCount(valSize)
            .testCount(total - trainSize - valSize)
            .build();
    }
    
    /**
     * æ•°æ®å¢å¼º
     */
    public void augmentDataset(Long datasetId, AugmentationConfig config) {
        List<Image> trainImages = imageMapper.selectList(
            new LambdaQueryWrapper<Image>()
                .eq(Image::getDatasetId, datasetId)
                .eq(Image::getSplit, "train")
        );
        
        for (Image image : trainImages) {
            // åº”ç”¨å¢å¼ºç­–ç•¥
            if (config.isHorizontalFlip() && Math.random() < 0.5) {
                applyHorizontalFlip(image);
            }
            if (config.isVerticalFlip() && Math.random() < 0.5) {
                applyVerticalFlip(image);
            }
            if (config.isRotation()) {
                applyRotation(image, config.getRotationAngle());
            }
            // ... å…¶ä»–å¢å¼ºæ“ä½œ
        }
    }
}
```

### 4.3 æ¨ç†æœåŠ¡ (cloud-inference)

#### 4.3.1 æ¨ç†ä»»åŠ¡ç®¡ç†

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class InferenceService {
    
    private final PythonInferenceClient pythonClient;
    private final DetectionJobMapper jobMapper;
    private final DetectionResultMapper resultMapper;
    private final MinioService minioService;
    private final RedisTemplate<String, Object> redisTemplate;
    
    /**
     * åˆ›å»ºæ¨ç†ä»»åŠ¡
     */
    @Transactional(rollbackFor = Exception.class)
    public InferenceJobResponse createInferenceJob(
            InferenceJobRequest request, Long userId) {
        
        log.info("åˆ›å»ºæ¨ç†ä»»åŠ¡ï¼Œç”¨æˆ·ID: {}", userId);
        
        // 1. åˆ›å»ºä»»åŠ¡è®°å½•
        DetectionJob job = DetectionJob.builder()
            .userId(userId)
            .imageUrl(request.getImageUrl())
            .modelVersion(request.getModelVersion())
            .status(JobStatus.PENDING)
            .config(JSON.toJSONString(request.getConfig()))
            .build();
        jobMapper.insert(job);
        
        // 2. å¼‚æ­¥è°ƒç”¨Pythonæ¨ç†æœåŠ¡
        CompletableFuture.runAsync(() -> {
            try {
                executeInference(job);
            } catch (Exception e) {
                log.error("æ¨ç†å¤±è´¥", e);
                updateJobStatus(job.getId(), JobStatus.FAILED, e.getMessage());
            }
        });
        
        return InferenceJobResponse.builder()
            .jobId(job.getId())
            .status(job.getStatus())
            .createdAt(job.getCreatedAt())
            .build();
    }
    
    /**
     * æ‰§è¡Œæ¨ç†
     */
    private void executeInference(DetectionJob job) {
        log.info("å¼€å§‹æ‰§è¡Œæ¨ç†ï¼Œä»»åŠ¡ID: {}", job.getId());
        
        // 1. æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
        updateJobStatus(job.getId(), JobStatus.RUNNING, null);
        
        // 2. ä¸‹è½½å›¾åƒ
        InputStream imageStream = minioService.getObject(job.getImageUrl());
        MultipartFile file = convertToMultipartFile(imageStream, "image.jpg");
        
        // 3. è°ƒç”¨PythonæœåŠ¡
        InferenceConfig config = JSON.parseObject(
            job.getConfig(), InferenceConfig.class);
        
        PythonInferenceRequest pythonRequest = PythonInferenceRequest.builder()
            .threshold(config.getThreshold())
            .minArea(config.getMinArea())
            .returnMask(true)
            .returnVectors(true)
            .returnAttributes(true)
            .build();
        
        PythonInferenceResponse pythonResponse = 
            pythonClient.detect(file, pythonRequest);
        
        // 4. ä¿å­˜ç»“æœ
        DetectionResult result = DetectionResult.builder()
            .jobId(job.getId())
            .maskUrl(pythonResponse.getMaskUrl())
            .overlayUrl(pythonResponse.getOverlayUrl())
            .vectors(JSON.toJSONString(pythonResponse.getVectors()))
            .attributes(JSON.toJSONString(pythonResponse.getAttributes()))
            .confidence(pythonResponse.getConfidence())
            .processingTime(pythonResponse.getProcessingTime())
            .build();
        resultMapper.insert(result);
        
        // 5. æ›´æ–°ä»»åŠ¡çŠ¶æ€
        updateJobStatus(job.getId(), JobStatus.COMPLETED, null);
        job.setResultId(result.getId());
        jobMapper.updateById(job);
        
        // 6. ç¼“å­˜ç»“æœåˆ°Redis
        cacheResult(job.getId(), result);
        
        log.info("æ¨ç†å®Œæˆï¼Œä»»åŠ¡ID: {}", job.getId());
    }
    
    /**
     * æ‰¹é‡æ¨ç†
     */
    public BatchInferenceResponse batchInference(
            BatchInferenceRequest request, Long userId) {
        
        List<Long> jobIds = new ArrayList<>();
        
        for (String imageUrl : request.getImageUrls()) {
            InferenceJobRequest jobRequest = InferenceJobRequest.builder()
                .imageUrl(imageUrl)
                .modelVersion(request.getModelVersion())
                .config(request.getConfig())
                .build();
            
            InferenceJobResponse response = createInferenceJob(jobRequest, userId);
            jobIds.add(response.getJobId());
        }
        
        return BatchInferenceResponse.builder()
            .batchId(UUID.randomUUID().toString())
            .totalJobs(jobIds.size())
            .jobIds(jobIds)
            .status("submitted")
            .build();
    }
    
    /**
     * è·å–æ¨ç†ç»“æœ
     */
    public DetectionResultResponse getInferenceResult(Long jobId) {
        // 1. å…ˆä»ç¼“å­˜è·å–
        String cacheKey = "inference:result:" + jobId;
        DetectionResult cachedResult = (DetectionResult) 
            redisTemplate.opsForValue().get(cacheKey);
        
        if (cachedResult != null) {
            return convertToResponse(cachedResult);
        }
        
        // 2. ä»æ•°æ®åº“è·å–
        DetectionJob job = jobMapper.selectById(jobId);
        if (job == null) {
            throw new ResourceNotFoundException("ä»»åŠ¡ä¸å­˜åœ¨");
        }
        
        if (job.getStatus() != JobStatus.COMPLETED) {
            return DetectionResultResponse.builder()
                .jobId(jobId)
                .status(job.getStatus())
                .build();
        }
        
        DetectionResult result = resultMapper.selectById(job.getResultId());
        return convertToResponse(result);
    }
    
    /**
     * è·å–ä»»åŠ¡åˆ—è¡¨
     */
    public Page<DetectionJobVO> listJobs(Long userId, JobListQuery query) {
        Page<DetectionJob> page = new Page<>(query.getPage(), query.getSize());
        
        LambdaQueryWrapper<DetectionJob> wrapper = new LambdaQueryWrapper<>();
        wrapper.eq(DetectionJob::getUserId, userId);
        
        if (query.getStatus() != null) {
            wrapper.eq(DetectionJob::getStatus, query.getStatus());
        }
        
        if (StringUtils.hasText(query.getModelVersion())) {
            wrapper.eq(DetectionJob::getModelVersion, query.getModelVersion());
        }
        
        wrapper.orderByDesc(DetectionJob::getCreatedAt);
        
        Page<DetectionJob> resultPage = jobMapper.selectPage(page, wrapper);
        
        return resultPage.convert(this::convertToVO);
    }
}
```

#### 4.3.2 Pythonæ¨ç†æœåŠ¡å®¢æˆ·ç«¯

```java
/**
 * Pythonæ¨ç†æœåŠ¡Feignå®¢æˆ·ç«¯
 */
@FeignClient(
    name = "python-inference",
    url = "${python.inference.url}",
    configuration = PythonInferenceFeignConfig.class
)
public interface PythonInferenceClient {
    
    @PostMapping(
        value = "/api/v1/inference/detect",
        consumes = MediaType.MULTIPART_FORM_DATA_VALUE
    )
    PythonInferenceResponse detect(
        @RequestPart("file") MultipartFile file,
        @SpringQueryMap PythonInferenceRequest request
    );
    
    @GetMapping("/api/v1/inference/result/{jobId}")
    PythonInferenceResponse getResult(@PathVariable("jobId") String jobId);
    
    @PostMapping("/api/v1/inference/batch")
    BatchInferenceResult batchDetect(
        @RequestBody BatchInferenceInput input
    );
    
    @GetMapping("/health")
    HealthCheckResponse healthCheck();
}

/**
 * Feigné…ç½®
 */
@Configuration
public class PythonInferenceFeignConfig {
    
    @Bean
    public RequestInterceptor requestInterceptor() {
        return template -> {
            template.header("X-Service-Name", "cloud-inference");
            template.header("X-Request-Id", UUID.randomUUID().toString());
        };
    }
    
    @Bean
    public Retryer retryer() {
        // æœ€å¤§é‡è¯•3æ¬¡ï¼Œåˆå§‹é—´éš”100msï¼Œæœ€å¤§é—´éš”1s
        return new Retryer.Default(100, 1000, 3);
    }
    
    @Bean
    public ErrorDecoder errorDecoder() {
        return (methodKey, response) -> {
            if (response.status() >= 400 && response.status() < 500) {
                return new BusinessException("PythonæœåŠ¡è¯·æ±‚å¤±è´¥");
            }
            if (response.status() >= 500) {
                return new ServiceUnavailableException("PythonæœåŠ¡ä¸å¯ç”¨");
            }
            return new Exception("æœªçŸ¥é”™è¯¯");
        };
    }
}
```

### 4.4 å¯è§†åŒ–æœåŠ¡ (cloud-visual)

```java
@Service
@RequiredArgsConstructor
public class VisualizationService {
    
    private final MinioService minioService;
    private final DetectionResultMapper resultMapper;
    
    /**
     * ç”Ÿæˆå åŠ å›¾åƒ
     */
    public String generateOverlayImage(Long resultId, OverlayConfig config) {
        // 1. è·å–æ£€æµ‹ç»“æœ
        DetectionResult result = resultMapper.selectById(resultId);
        
        // 2. ä¸‹è½½åŸå›¾å’Œæ©ç 
        BufferedImage originalImage = loadImage(result.getImageUrl());
        BufferedImage maskImage = loadImage(result.getMaskUrl());
        
        // 3. åˆ›å»ºå åŠ å›¾åƒ
        BufferedImage overlayImage = new BufferedImage(
            originalImage.getWidth(),
            originalImage.getHeight(),
            BufferedImage.TYPE_INT_ARGB
        );
        
        Graphics2D g2d = overlayImage.createGraphics();
        
        // ç»˜åˆ¶åŸå›¾
        g2d.drawImage(originalImage, 0, 0, null);
        
        // ç»˜åˆ¶åŠé€æ˜æ©ç 
        g2d.setComposite(AlphaComposite.getInstance(
            AlphaComposite.SRC_OVER, config.getAlpha()));
        g2d.setColor(config.getMaskColor());
        
        // åº”ç”¨æ©ç 
        for (int y = 0; y < maskImage.getHeight(); y++) {
            for (int x = 0; x < maskImage.getWidth(); x++) {
                int rgb = maskImage.getRGB(x, y);
                if ((rgb & 0xFF) > 128) { // ç™½è‰²åƒç´ 
                    g2d.fillRect(x, y, 1, 1);
                }
            }
        }
        
        // ç»˜åˆ¶è½®å»“
        if (config.isDrawContours()) {
            drawContours(g2d, result.getVectors());
        }
        
        // ç»˜åˆ¶æ ‡æ³¨
        if (config.isDrawAnnotations()) {
            drawAnnotations(g2d, result.getAttributes());
        }
        
        g2d.dispose();
        
        // 4. ä¿å­˜åˆ°MinIO
        String overlayUrl = saveOverlayImage(resultId, overlayImage);
        
        // 5. æ›´æ–°ç»“æœè®°å½•
        result.setOverlayUrl(overlayUrl);
        resultMapper.updateById(result);
        
        return overlayUrl;
    }
    
    /**
     * ç”Ÿæˆçƒ­åŠ›å›¾
     */
    public String generateHeatmap(Long resultId, HeatmapConfig config) {
        DetectionResult result = resultMapper.selectById(resultId);
        
        // åŠ è½½ç½®ä¿¡åº¦å›¾
        float[][] confidenceMap = loadConfidenceMap(result.getMaskUrl());
        
        // åº”ç”¨é¢œè‰²æ˜ å°„
        BufferedImage heatmap = applyColorMap(
            confidenceMap, 
            config.getColorMap()
        );
        
        // ä¿å­˜çƒ­åŠ›å›¾
        String heatmapUrl = saveHeatmap(resultId, heatmap);
        
        return heatmapUrl;
    }
    
    /**
     * ç”Ÿæˆç»Ÿè®¡å›¾è¡¨
     */
    public ChartData generateStatistics(Long resultId) {
        DetectionResult result = resultMapper.selectById(resultId);
        
        List<CrackAttribute> attributes = JSON.parseArray(
            result.getAttributes(), CrackAttribute.class);
        
        // ç»Ÿè®¡è£‚çº¹ç±»å‹åˆ†å¸ƒ
        Map<String, Long> typeDistribution = attributes.stream()
            .collect(Collectors.groupingBy(
                CrackAttribute::getType,
                Collectors.counting()
            ));
        
        // ç»Ÿè®¡ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
        Map<String, Long> severityDistribution = attributes.stream()
            .collect(Collectors.groupingBy(
                CrackAttribute::getSeverity,
                Collectors.counting()
            ));
        
        // è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        DoubleSummaryStatistics lengthStats = attributes.stream()
            .mapToDouble(CrackAttribute::getLength)
            .summaryStatistics();
        
        DoubleSummaryStatistics widthStats = attributes.stream()
            .mapToDouble(CrackAttribute::getWidth)
            .summaryStatistics();
        
        return ChartData.builder()
            .typeDistribution(typeDistribution)
            .severityDistribution(severityDistribution)
            .totalCracks(attributes.size())
            .totalLength(lengthStats.getSum())
            .avgWidth(widthStats.getAverage())
            .maxWidth(widthStats.getMax())
            .build();
    }
}
```

### 4.5 æŠ¥å‘Šç”ŸæˆæœåŠ¡ (cloud-report)

```java
@Service
@RequiredArgsConstructor
public class ReportGenerationService {
    
    private final DetectionResultMapper resultMapper;
    private final VisualizationService visualService;
    private final MinioService minioService;
    
    /**
     * ç”ŸæˆPDFæŠ¥å‘Š
     */
    public String generatePdfReport(Long resultId, ReportTemplate template) {
        // 1. è·å–æ£€æµ‹æ•°æ®
        DetectionResult result = resultMapper.selectById(resultId);
        ChartData statistics = visualService.generateStatistics(resultId);
        
        // 2. åˆ›å»ºPDFæ–‡æ¡£
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        PdfWriter writer = new PdfWriter(baos);
        PdfDocument pdf = new PdfDocument(writer);
        Document document = new Document(pdf, PageSize.A4);
        
        // 3. æ·»åŠ æ ‡é¢˜
        Paragraph title = new Paragraph("é“è·¯è£‚çº¹æ£€æµ‹æŠ¥å‘Š")
            .setFont(PdfFontFactory.createFont(StandardFonts.HELVETICA_BOLD))
            .setFontSize(20)
            .setTextAlignment(TextAlignment.CENTER);
        document.add(title);
        
        // 4. æ·»åŠ åŸºæœ¬ä¿¡æ¯
        Table infoTable = new Table(new float[]{2, 3});
        infoTable.addCell("æ£€æµ‹æ—¶é—´");
        infoTable.addCell(result.getCreatedAt().toString());
        infoTable.addCell("å›¾åƒåç§°");
        infoTable.addCell(result.getImageName());
        infoTable.addCell("å¤„ç†æ—¶é—´");
        infoTable.addCell(result.getProcessingTime() + "ç§’");
        infoTable.addCell("ç½®ä¿¡åº¦");
        infoTable.addCell(String.format("%.2f%%", result.getConfidence() * 100));
        document.add(infoTable);
        
        // 5. æ·»åŠ å›¾åƒ
        Image originalImage = new Image(
            ImageDataFactory.create(loadImageBytes(result.getImageUrl()))
        ).scaleToFit(400, 300);
        document.add(new Paragraph("åŸå§‹å›¾åƒ:"));
        document.add(originalImage);
        
        Image overlayImage = new Image(
            ImageDataFactory.create(loadImageBytes(result.getOverlayUrl()))
        ).scaleToFit(400, 300);
        document.add(new Paragraph("æ£€æµ‹ç»“æœ:"));
        document.add(overlayImage);
        
        // 6. æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        document.add(new Paragraph("æ£€æµ‹ç»“æœç»Ÿè®¡").setFontSize(16));
        Table statsTable = new Table(new float[]{2, 2});
        statsTable.addCell("è£‚çº¹æ€»æ•°");
        statsTable.addCell(statistics.getTotalCracks().toString());
        statsTable.addCell("æ€»é•¿åº¦");
        statsTable.addCell(String.format("%.2fç±³", statistics.getTotalLength()));
        statsTable.addCell("å¹³å‡å®½åº¦");
        statsTable.addCell(String.format("%.2fmm", statistics.getAvgWidth()));
        statsTable.addCell("æœ€å¤§å®½åº¦");
        statsTable.addCell(String.format("%.2fmm", statistics.getMaxWidth()));
        document.add(statsTable);
        
        // 7. æ·»åŠ è¯¦ç»†åˆ—è¡¨
        List<CrackAttribute> cracks = JSON.parseArray(
            result.getAttributes(), CrackAttribute.class);
        
        document.add(new Paragraph("è£‚çº¹è¯¦ç»†åˆ—è¡¨").setFontSize(16));
        Table crackTable = new Table(new float[]{1, 2, 2, 2, 2});
        crackTable.addHeaderCell("ID");
        crackTable.addHeaderCell("é•¿åº¦(m)");
        crackTable.addHeaderCell("å®½åº¦(mm)");
        crackTable.addHeaderCell("é¢ç§¯(mÂ²)");
        crackTable.addHeaderCell("ä¸¥é‡ç¨‹åº¦");
        
        for (int i = 0; i < cracks.size(); i++) {
            CrackAttribute crack = cracks.get(i);
            crackTable.addCell(String.valueOf(i + 1));
            crackTable.addCell(String.format("%.2f", crack.getLength()));
            crackTable.addCell(String.format("%.2f", crack.getWidth()));
            crackTable.addCell(String.format("%.4f", crack.getArea()));
            crackTable.addCell(crack.getSeverity());
        }
        document.add(crackTable);
        
        // 8. æ·»åŠ ç»´æŠ¤å»ºè®®
        document.add(new Paragraph("ç»´æŠ¤å»ºè®®").setFontSize(16));
        document.add(new Paragraph(generateMaintenanceAdvice(statistics)));
        
        // 9. å…³é—­æ–‡æ¡£
        document.close();
        
        // 10. ä¸Šä¼ åˆ°MinIO
        byte[] pdfBytes = baos.toByteArray();
        String pdfUrl = minioService.uploadBytes(
            pdfBytes,
            "reports",
            "report-" + resultId + ".pdf",
            "application/pdf"
        );
        
        return pdfUrl;
    }
    
    /**
     * ç”ŸæˆExcelæŠ¥å‘Š
     */
    public String generateExcelReport(Long resultId) {
        DetectionResult result = resultMapper.selectById(resultId);
        List<CrackAttribute> cracks = JSON.parseArray(
            result.getAttributes(), CrackAttribute.class);
        
        try (Workbook workbook = new XSSFWorkbook()) {
            // åˆ›å»ºå·¥ä½œè¡¨
            Sheet sheet = workbook.createSheet("è£‚çº¹æ£€æµ‹ç»“æœ");
            
            // åˆ›å»ºæ ‡é¢˜è¡Œ
            Row headerRow = sheet.createRow(0);
            String[] headers = {"ID", "é•¿åº¦(m)", "å®½åº¦(mm)", "é¢ç§¯(mÂ²)", 
                               "å‘¨é•¿(m)", "æ–¹å‘è§’(Â°)", "ä¸¥é‡ç¨‹åº¦"};
            for (int i = 0; i < headers.length; i++) {
                Cell cell = headerRow.createCell(i);
                cell.setCellValue(headers[i]);
            }
            
            // å¡«å……æ•°æ®
            for (int i = 0; i < cracks.size(); i++) {
                Row row = sheet.createRow(i + 1);
                CrackAttribute crack = cracks.get(i);
                
                row.createCell(0).setCellValue(i + 1);
                row.createCell(1).setCellValue(crack.getLength());
                row.createCell(2).setCellValue(crack.getWidth());
                row.createCell(3).setCellValue(crack.getArea());
                row.createCell(4).setCellValue(crack.getPerimeter());
                row.createCell(5).setCellValue(crack.getOrientation());
                row.createCell(6).setCellValue(crack.getSeverity());
            }
            
            // è‡ªåŠ¨è°ƒæ•´åˆ—å®½
            for (int i = 0; i < headers.length; i++) {
                sheet.autoSizeColumn(i);
            }
            
            // ä¿å­˜åˆ°å­—èŠ‚æ•°ç»„
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            workbook.write(baos);
            
            // ä¸Šä¼ åˆ°MinIO
            String excelUrl = minioService.uploadBytes(
                baos.toByteArray(),
                "reports",
                "report-" + resultId + ".xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            );
            
            return excelUrl;
            
        } catch (IOException e) {
            throw new BusinessException("ç”ŸæˆExcelæŠ¥å‘Šå¤±è´¥", e);
        }
    }
    
    /**
     * ç”Ÿæˆç»´æŠ¤å»ºè®®
     */
    private String generateMaintenanceAdvice(ChartData statistics) {
        StringBuilder advice = new StringBuilder();
        
        advice.append("æ ¹æ®æ£€æµ‹ç»“æœï¼Œæå‡ºä»¥ä¸‹ç»´æŠ¤å»ºè®®ï¼š\n\n");
        
        // æ ¹æ®è£‚çº¹æ•°é‡
        if (statistics.getTotalCracks() > 50) {
            advice.append("1. è£‚çº¹æ•°é‡è¾ƒå¤š(")
                  .append(statistics.getTotalCracks())
                  .append("æ¡)ï¼Œå»ºè®®è¿›è¡Œå…¨é¢ç»´æŠ¤ã€‚\n");
        } else if (statistics.getTotalCracks() > 20) {
            advice.append("1. è£‚çº¹æ•°é‡ä¸­ç­‰ï¼Œå»ºè®®é‡ç‚¹ä¿®å¤ä¸¥é‡è£‚çº¹ã€‚\n");
        } else {
            advice.append("1. è£‚çº¹æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®å®šæœŸç›‘æµ‹ã€‚\n");
        }
        
        // æ ¹æ®ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
        long severeCount = statistics.getSeverityDistribution()
            .getOrDefault("severe", 0L);
        if (severeCount > 0) {
            advice.append("2. å‘ç° ").append(severeCount)
                  .append(" æ¡ä¸¥é‡è£‚çº¹ï¼Œå»ºè®®ç«‹å³ä¿®å¤ã€‚\n");
        }
        
        // æ ¹æ®å¹³å‡å®½åº¦
        if (statistics.getAvgWidth() > 5.0) {
            advice.append("3. è£‚çº¹å¹³å‡å®½åº¦è¾ƒå¤§(")
                  .append(String.format("%.2fmm", statistics.getAvgWidth()))
                  .append(")ï¼Œå»ºè®®é‡‡ç”¨çŒç¼æˆ–è´´ç¼å¤„ç†ã€‚\n");
        }
        
        advice.append("\né¢„è®¡ç»´æŠ¤æˆæœ¬ï¼š");
        double estimatedCost = calculateMaintenanceCost(statistics);
        advice.append(String.format("%.2få…ƒ", estimatedCost));
        
        return advice.toString();
    }
    
    private double calculateMaintenanceCost(ChartData statistics) {
        // ç®€åŒ–çš„æˆæœ¬è®¡ç®—æ¨¡å‹
        double baseCost = 50.0; // åŸºç¡€æˆæœ¬/æ¡
        double lengthFactor = 10.0; // é•¿åº¦å› å­ å…ƒ/ç±³
        double severityMultiplier = statistics.getSeverityDistribution()
            .getOrDefault("severe", 0L) * 1.5;
        
        return statistics.getTotalCracks() * baseCost +
               statistics.getTotalLength() * lengthFactor +
               severityMultiplier * 100;
    }
}
```

---

## 4x. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ï¼ˆç®—æ³•ä¾§ï¼‰

### 4x.1 æ•°æ®è§„èŒƒä¸ç›®å½•

```
data/
â”œâ”€â”€ raw/                         # åŸå§‹æ•°æ®ï¼ˆRDD2022/Crack500/è‡ªé‡‡é›†ï¼‰
â”‚   â”œâ”€â”€ images/{scene}/{id}.jpg
â”‚   â””â”€â”€ annotations/{id}.{json|xml|txt|png}
â”œâ”€â”€ interim/                     # ä¸­é—´äº§ç‰©ï¼ˆç»Ÿä¸€æ ‡æ³¨ã€åˆ‡ç‰‡ã€è¿‡æ»¤ï¼‰
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â”œâ”€â”€ processed/                   # è®­ç»ƒå¯ç›´æ¥ä½¿ç”¨çš„æ•°æ®
â”‚   â”œâ”€â”€ train/{images,masks}
â”‚   â”œâ”€â”€ val/{images,masks}
â”‚   â””â”€â”€ test/{images,masks}
â””â”€â”€ meta/
    â”œâ”€â”€ dataset.yaml            # æ•°æ®é›†é…ç½®ï¼ˆç±»åˆ«ã€åƒç´ ç»Ÿè®¡ã€é…æ¯”ï¼‰
    â”œâ”€â”€ stats.json              # ç»Ÿè®¡ï¼ˆé¢ç§¯/å®½åº¦ç›´æ–¹å›¾ã€è£‚çº¹é•¿åº¦åˆ†å¸ƒï¼‰
    â””â”€â”€ version.json            # ç‰ˆæœ¬ä¿¡æ¯ï¼ˆDVCé£æ ¼ï¼‰
```

å…³é”®è§„èŒƒï¼š
- å›¾åƒç»Ÿä¸€ä¸º RGBï¼Œè‰²å½©ç©ºé—´ sRGBï¼›æ©ç ä¸ºå•é€šé“ 0/255ï¼ˆæˆ–0/1ï¼‰
- ç»Ÿä¸€åˆ†è¾¨ç‡è®­ç»ƒå°ºå¯¸ï¼šå¤šå°ºåº¦ç­–ç•¥ 256/384/512 æ··åˆï¼›é«˜åˆ†è¾¨ç‡æ¨ç†é‡‡ç”¨æ»‘çª—æ‹¼æ¥
- ç»Ÿä¸€æ ‡æ³¨ï¼šCOCO/VOC/YOLO/PNG æ©ç å…¨éƒ¨è½¬æ¢ä¸ºäºŒå€¼æ©ç ï¼Œä¿ç•™ instance map å¯é€‰

### 4x.2 æ ‡æ³¨è½¬æ¢ä¸è´¨é‡æ§åˆ¶

- è½¬æ¢å™¨ï¼šCOCO/VOC/YOLO â†’ PNG maskï¼Œæ”¯æŒ polygonâ†’rasterizeï¼Œhole/overlap ä¿®æ­£
- è´¨é‡æ ¡éªŒï¼š
  - æ©ç -å›¾åƒå°ºå¯¸ä¸€è‡´æ€§æ£€æŸ¥
  - å°é¢ç§¯ä¼ªæ ‡æ³¨å‰”é™¤ï¼ˆé¢ç§¯é˜ˆå€¼ã€ç»†åº¦æ¯”ã€ç»†é•¿æ¯”ç­‰å½¢æ€å­¦æŒ‡æ ‡ï¼‰
  - æ¼æ ‡/é”™æ ‡è‡ªåŠ¨å®¡è®¡ï¼ˆåŸºäºæ•™å¸ˆæ¨¡å‹å¼±ç›‘ç£ç½®ä¿¡å›¾æ¯”å¯¹ï¼‰

### 4x.3 æ ·æœ¬åˆ’åˆ†ä¸é‡‡æ ·

- åˆ†å±‚åˆ’åˆ†ï¼šæŒ‰åœºæ™¯ã€å¤©æ°”ã€è·¯å‹ã€ç›¸æœºè®¾å¤‡åˆ†å±‚ï¼Œä¿æŒåˆ†å¸ƒä¸€è‡´ï¼ˆTrain 70/Val 15/Test 15ï¼‰
- éš¾ä¾‹å¼ºåŒ–é‡‡æ ·ï¼ˆHard Example Miningï¼‰ï¼šæŒ‰IoU/è¾¹ç•Œè¯¯å·®å†å²ç»Ÿè®¡ï¼Œå¯¹é«˜è¯¯å·®æ ·æœ¬åŠ æƒé‡‡æ ·
- ç±»åˆ«/å½¢æ€å†å¹³è¡¡ï¼šæŒ‰è£‚çº¹å®½åº¦/é•¿åº¦åˆ†å¸ƒåš reweight ä¸ oversampleï¼Œä¿è¯å°ç›®æ ‡/ç»†è£‚çº¹è¦†ç›–

### 4x.4 æ•°æ®å¢å¼ºï¼ˆAlbumentationsï¼Œåˆ†å‰²å‹å¥½å‹ï¼‰

- å‡ ä½•å¢å¼ºï¼šRandomScale(0.5~2.0)ã€RandomRotate90ã€Affineï¼ˆä¿æŒæ‹“æ‰‘ï¼‰ã€ElasticTransformï¼ˆè½»åº¦ï¼‰
- é¢œè‰²å¢å¼ºï¼šCLAHEã€RandomBrightnessContrastã€HueSaturationValueã€ColorJitterï¼ˆå¼±åˆ°ä¸­ç­‰ï¼‰
- å™ªå£°/å¤©æ°”ï¼šGaussNoiseã€MotionBlurã€ISO Noiseã€Rain/Snow/Fogï¼ˆåˆæˆå¤©æ°”åº“ï¼Œå¯é€‰ï¼‰
- CutMix/Copy-Pasteï¼ˆåˆ†å‰²ç‰ˆï¼‰ï¼šå°†ç»†è£‚çº¹ç‰‡æ®µç²˜è´´åˆ°åŒåŸŸå›¾åƒï¼Œå¢å¼ºé•¿æ¡/ç¨€ç–æ¨¡å¼
- è¾¹ç•Œä¿æŒï¼šæ‰€æœ‰å‡ ä½•å¢å¼ºå¯¹ mask ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼ï¼Œé˜²æ­¢è¾¹ç•Œç°åŒ–

å¢å¼ºç­–ç•¥ï¼ˆå¼º/å¼±ï¼‰ï¼š
- è®­ç»ƒå‰ 60% epoch ä½¿ç”¨å¼ºå¢å¼ºï¼ˆå«Elasticã€Copy-Pasteï¼‰ï¼Œå 40% é™çº§ä¸ºå¼±å¢å¼ºç¨³å®šæ”¶æ•›

### 4x.5 é«˜åˆ†è¾¨ç‡å¤„ç†ä¸æ»‘çª—æ¨ç†

- è®­ç»ƒï¼šéšæœºè£å‰ª 512Ã—512 æˆ– 768Ã—768ï¼Œå¸¦ 64~128 åƒç´  overlapï¼Œä¿è¯è¾¹ç•Œå¯è§
- æ¨ç†ï¼š
  - æ»‘çª—å¤§å° 1024Ã—1024ï¼Œoverlap=1/6~1/4ï¼Œçª—å£åˆå¹¶é‡‡ç”¨ Gaussian åŠ æƒèåˆ
  - TTAï¼šæ°´å¹³/å‚ç›´ç¿»è½¬+å¤šå°ºåº¦ï¼ˆ0.75/1.0/1.25ï¼‰ï¼Œç»“æœåå˜æ¢å¹³å‡

### 4x.6 å½’ä¸€åŒ–ä¸æ ‡å‡†åŒ–

- å½’ä¸€åŒ–ï¼šImageNet mean/stdï¼ˆæˆ–æŒ‰æ•°æ®é›†ç»Ÿè®¡åŠ¨æ€è®¡ç®—ï¼‰
- å…‰ç…§æ ‡å‡†åŒ–ï¼šç°åº¦/äº®åº¦ç›´æ–¹å›¾åŒ¹é…ï¼ˆå¯é€‰ï¼‰ï¼Œå‡å°‘ç›¸æœºä¸æ—¶æ®µåç§»

### 4x.7 é«˜æ•ˆæ•°æ®åŠ è½½ï¼ˆPyTorchï¼‰

- DataLoaderï¼šnum_workers=4~8ï¼Œprefetch_factor=2ï¼Œpin_memory=True
- ç¼“å­˜ï¼šå°å‹ LMDB/RecordIO ç¼“å­˜ä¸­é—´è£ç‰‡ï¼ŒI/O å—é™æ—¶å¯ç”¨
- æ··åˆç²¾åº¦ä¸æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼šé™ä½æ˜¾å­˜ï¼Œæé«˜åå


## 4y. æ¨¡å‹ç®—æ³•è®¾è®¡ä¸è°ƒä¼˜ï¼ˆSOTAå‚è€ƒï¼‰

### 4y.1 ä»»åŠ¡æ‹†åˆ†

- Pixel-level Crack Segmentationï¼ˆä¸»ä»»åŠ¡ï¼‰
- Boundary-aware Refinementï¼ˆè¾¹ç•Œç»†åŒ–ï¼‰
- Attribute Regressionï¼ˆå®½åº¦/æ–¹å‘/é•¿åº¦åéªŒä¼°è®¡ï¼Œåå¤„ç†é˜¶æ®µè®¡ç®—ä¸ºä¸»ï¼‰

### 4y.2 æ¨¡å‹å€™é€‰ä¸ç»„åˆ

åˆ†ä¸‰æ¡£æ¨¡å‹ï¼Œå…¼é¡¾ç²¾åº¦ä¸é€Ÿåº¦ï¼š

- è½»é‡çº§ï¼ˆå®æ—¶/è¾¹ç¼˜ï¼‰ï¼šBiSeNetV2 / Fast-SCNN / SegFormer-B0/1ï¼ˆMiT-B0/1ï¼‰
- å¹³è¡¡å‹ï¼ˆé»˜è®¤ç”Ÿäº§ï¼‰ï¼šU-Net++(CBAM + ASPP) with ConvNeXt-T/S encoder æˆ– SegFormer-B2
- é«˜ç²¾åº¦ï¼ˆç¦»çº¿/æ‰¹å¤„ç†ï¼‰ï¼šHRNetV2-W32 + OCR head / SegFormer-B4/B5 / ConvNeXt-L encoder + DeepLabV3+

æ¨èé»˜è®¤ï¼š
- Backbone: ConvNeXt-T/S æˆ– Swin-Tï¼ˆå°å‹ Transformerï¼‰
- Head: UPerHead æˆ– DeepLabV3+ï¼ˆASPPï¼‰/ Lightweight OCRï¼ˆè¾¹ç•Œæ•æ„Ÿï¼‰

### 4y.3 è¾¹ç•Œå¢å¼ºä¸å¤šä»»åŠ¡å¤´

- è¾¹ç•Œåˆ†æ”¯ï¼šä»ä¸­é—´å±‚æå–ç‰¹å¾ç» Sobel/Laplacian å¼•å¯¼ï¼Œé¢„æµ‹ Edge mapï¼›æ€»æŸå¤±åŠ å…¥ Boundary loss
- Thin-object å¼ºåŒ–ï¼šCoordConv + Strip Poolingï¼ˆç»†é•¿ç»“æ„æ„Ÿå—é‡ï¼‰
- æ·±åº¦ç›‘ç£ï¼šå¤šå°ºåº¦è¾“å‡ºï¼ˆ1/4, 1/8, 1/16ï¼‰è¾…åŠ©åˆ†æ”¯ï¼Œæå‡æ”¶æ•›ä¸ç»†èŠ‚

### 4y.4 æŸå¤±å‡½æ•°ç»„åˆï¼ˆç±»åˆ«æä¸å‡è¡¡ä¸ç»†è¾¹ç•Œï¼‰

- ä¸»å¹²ï¼šDice Lossï¼ˆSoftï¼‰ + Focal Lossï¼ˆÎ³=1.5~2.0ï¼‰+ BCEWithLogits
- è¾¹ç•Œï¼šBoundary Lossï¼ˆSDF/Tversky å˜ä½“ï¼‰æˆ– Lovasz-Hingeï¼ˆå¯¹IoUå‹å¥½ï¼‰
- Tversky(Î±=0.5, Î²=0.7) æˆ– Focal-Tversky åº”å¯¹æ¼æ£€>è¯¯æ£€åœºæ™¯

æ€»æŸå¤±ï¼š
L = 0.4Â·Dice + 0.3Â·Focal + 0.2Â·BCE + 0.1Â·Boundary

### 4y.5 è®­ç»ƒé…æ–¹ï¼ˆé«˜æ€§èƒ½ï¼‰

- ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆwd=1e-4ï¼‰æˆ– Lionï¼ˆé€‚åˆViT/ConvNeXtï¼‰
- å­¦ä¹ ç‡ï¼šOneCycleLR æˆ– CosineAnnealingLRï¼ˆwarmup 5% stepsï¼‰
- æ‰¹é‡ï¼š16~32ï¼ˆAMPå¼€å¯ï¼‰ï¼Œæ¢¯åº¦ç´¯ç§¯æ”¯æŒç­‰æ•ˆæ›´å¤§ batch
- æ­£åˆ™ï¼šDropPath/Stochastic Depth=0.1~0.2ï¼ˆTransformer/ConvNeXtï¼‰ï¼ŒLabel Smoothing=0.05
- æ­£äº¤æŠ€å·§ï¼š
  - EMAï¼ˆdecay=0.9995ï¼‰æå‡æ³›åŒ–
  - SWAï¼ˆæœ€å10% epochï¼‰
  - Gradient Checkpointingï¼ˆViT/å¤§æ¨¡å‹ï¼‰èŠ‚çœæ˜¾å­˜
  - SyncBN/GroupNormï¼ˆå¤šå¡/å°batchï¼‰

è®­ç»ƒæ—¥ç¨‹ï¼ˆç¤ºä¾‹ï¼Œ200 epochsï¼‰ï¼š
- 0~120: å¼ºå¢å¼º + å¤šå°ºåº¦ + é«˜LR
- 120~180: é™çº§å¢å¼º + å›ºå®šå°ºåº¦ï¼ˆ512ï¼‰ç¨³å®šæ”¶æ•›
- 180~200: SWA/EMA consolidate + æœ€ä¼˜æƒé‡é€‰æ‹©ï¼ˆæŒ‰Val IoUï¼‰

### 4y.6 è¯„ä»·ä¸é€‰æ‹©

- æŒ‡æ ‡ï¼šmIoUã€Boundary F1(BF-score)ã€Thin-Region IoUï¼ˆå®½åº¦<3px åŒºåŸŸï¼‰
- æ—©åœï¼špatience=20ï¼Œç›‘æ§ Val mIoU ä¸ BF-score å…±åŒé˜ˆå€¼
- ç½®ä¿¡åº¦æ ‡å®šï¼šTemperature Scalingï¼ˆæ¨ç†è¾“å‡ºé˜ˆå€¼è‡ªé€‚åº”ï¼‰

### 4y.7 æ¨ç†ä¸å‹ç¼©

- å¯¼å‡ºï¼šPyTorch â†’ ONNXï¼ˆopsetâ‰¥17ï¼‰â†’ TensorRTï¼ˆFP16/INT8ï¼‰
- é‡åŒ–ï¼šPTQï¼ˆç›´æ–¹å›¾/æœ€å°MSEï¼‰æˆ– QATï¼ˆæœ€å20~40 epochs å¾®è°ƒï¼‰
- ç¨€ç–+å‰ªæï¼šL1é€šé“å‰ªæ+ç»“æ„é‡å‚æ•°åŒ–ï¼ˆRepVGG-style conv foldingï¼‰
- TTA ä¸ æ»‘çª—èåˆï¼šå¦‚ä¸Š 4x.5

### 4y.8 åå¤„ç†ä¸å±æ€§æå–

- è¿é€šåŸŸç­›é€‰ï¼šé¢ç§¯ã€ç»†åº¦ã€ç»†é•¿æ¯”è¿‡æ»¤å°ä¼ªå½±
- ç»†åŒ–ï¼šMorphologyï¼ˆopen/close/skeletonizationï¼‰+ Zhang-Suen ç»†åŒ–æéª¨æ¶
- å®½åº¦ä¼°è®¡ï¼šè·ç¦»å˜æ¢ + å±€éƒ¨æ­£äº¤çº¿æ‹Ÿåˆä¼°è®¡åƒç´ å®½åº¦
- å‘é‡åŒ–ï¼šDouglas-Peucker è½®å»“ç®€åŒ–ï¼›å¯¼å‡ºä¸º GeoJSON/Shapely LineStringï¼ˆå¯å åŠ GISï¼‰

### 4y.9 åŠç›‘ç£/è‡ªè®­ç»ƒï¼ˆå¯é€‰ï¼‰

- Teacher-Studentï¼šé«˜ç½®ä¿¡æ ·æœ¬ä¼ªæ ‡ç­¾åŠ å…¥è®­ç»ƒï¼Œé˜ˆå€¼ 0.8ï¼›å¯¹ä¸ç¡®å®šåŒºåŸŸä½¿ç”¨ consistency loss
- æ•°æ®åˆæˆï¼šçº¹ç†è¿ç§»ï¼ˆStyleAugï¼‰+ Copy-Paste æ‰©å……ç¨€ç¼ºè£‚çº¹å½¢æ€

### 4y.10 è¶…å‚ä¸åŸºçº¿é…ç½®ï¼ˆç¤ºä¾‹ï¼‰

```
model:
  backbone: convnext_tiny
  head: upernet           # æˆ– deeplabv3+
  deep_supervision: true
  edge_branch: true

data:
  crop_size: [512, 512]
  train_scales: [256, 384, 512]
  tta_scales: [0.75, 1.0, 1.25]
  overlap: 96

train:
  epochs: 200
  batch_size: 16
  optimizer: adamw
  lr: 1e-3
  weight_decay: 1e-4
  scheduler: cosine
  amp: true
  ema: true
  swa: true

loss:
  dice: 0.4
  focal: 0.3
  bce: 0.2
  boundary: 0.1
```


## 5. æ•°æ®åº“è®¾è®¡

### 5.1 æ•°æ®åº“é€‰å‹

é€‰æ‹©**PostgreSQL 15**ä½œä¸ºä¸»æ•°æ®åº“ï¼š
- âœ… æ”¯æŒJSON/JSONBç±»å‹ï¼Œå­˜å‚¨çµæ´»
- âœ… æ”¯æŒGISæ‰©å±•ï¼ˆPostGISï¼‰ï¼Œå¯å­˜å‚¨åœ°ç†ä½ç½®
- âœ… æ”¯æŒå…¨æ–‡æ£€ç´¢
- âœ… ACIDç‰¹æ€§å®Œå¤‡
- âœ… æ€§èƒ½ä¼˜å¼‚

### 5.2 æ ¸å¿ƒè¡¨è®¾è®¡

#### 5.2.1 ç”¨æˆ·ä¸æƒé™è¡¨

```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE sys_user (
    id BIGSERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    password VARCHAR(255) NOT NULL,
    email VARCHAR(100) UNIQUE,
    phone VARCHAR(20),
    avatar_url VARCHAR(500),
    status SMALLINT DEFAULT 1, -- 0:ç¦ç”¨ 1:å¯ç”¨
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login_at TIMESTAMP
);

-- è§’è‰²è¡¨
CREATE TABLE sys_role (
    id BIGSERIAL PRIMARY KEY,
    role_name VARCHAR(50) NOT NULL,
    role_code VARCHAR(50) UNIQUE NOT NULL,
    description TEXT,
    status SMALLINT DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æƒé™è¡¨
CREATE TABLE sys_permission (
    id BIGSERIAL PRIMARY KEY,
    permission_name VARCHAR(100) NOT NULL,
    permission_code VARCHAR(100) UNIQUE NOT NULL,
    resource_type VARCHAR(20), -- menu, button, api
    resource_path VARCHAR(500),
    method VARCHAR(10), -- GET, POST, PUT, DELETE
    parent_id BIGINT DEFAULT 0,
    sort_order INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç”¨æˆ·-è§’è‰²å…³è”è¡¨
CREATE TABLE sys_user_role (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    role_id BIGINT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, role_id),
    FOREIGN KEY (user_id) REFERENCES sys_user(id) ON DELETE CASCADE,
    FOREIGN KEY (role_id) REFERENCES sys_role(id) ON DELETE CASCADE
);

-- è§’è‰²-æƒé™å…³è”è¡¨
CREATE TABLE sys_role_permission (
    id BIGSERIAL PRIMARY KEY,
    role_id BIGINT NOT NULL,
    permission_id BIGINT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(role_id, permission_id),
    FOREIGN KEY (role_id) REFERENCES sys_role(id) ON DELETE CASCADE,
    FOREIGN KEY (permission_id) REFERENCES sys_permission(id) ON DELETE CASCADE
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_user_username ON sys_user(username);
CREATE INDEX idx_user_email ON sys_user(email);
CREATE INDEX idx_user_status ON sys_user(status);
CREATE INDEX idx_user_role_user ON sys_user_role(user_id);
CREATE INDEX idx_user_role_role ON sys_user_role(role_id);
```

#### 5.2.2 æ•°æ®é›†ç›¸å…³è¡¨

```sql
-- æ•°æ®é›†è¡¨
CREATE TABLE dataset (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    source VARCHAR(100), -- rdd2022, crack500, custom, upload
    version VARCHAR(50),
    format VARCHAR(50), -- coco, voc, yolo, custom
    
    total_images INT DEFAULT 0,
    train_count INT DEFAULT 0,
    val_count INT DEFAULT 0,
    test_count INT DEFAULT 0,
    
    storage_path VARCHAR(500),
    
    metadata JSONB, -- å­˜å‚¨é¢å¤–çš„å…ƒæ•°æ®
    
    status VARCHAR(20) DEFAULT 'pending', -- pending, processing, ready, failed
    
    created_by BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (created_by) REFERENCES sys_user(id)
);

-- å›¾åƒè¡¨
CREATE TABLE image (
    id BIGSERIAL PRIMARY KEY,
    dataset_id BIGINT NOT NULL,
    
    filename VARCHAR(255) NOT NULL,
    original_path VARCHAR(500),
    processed_path VARCHAR(500),
    
    width INT,
    height INT,
    format VARCHAR(20), -- jpg, png
    file_size BIGINT, -- å­—èŠ‚
    
    split VARCHAR(20), -- train, val, test
    has_annotation BOOLEAN DEFAULT FALSE,
    
    metadata JSONB,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (dataset_id) REFERENCES dataset(id) ON DELETE CASCADE
);

-- æ ‡æ³¨è¡¨
CREATE TABLE annotation (
    id BIGSERIAL PRIMARY KEY,
    image_id BIGINT NOT NULL,
    
    annotation_type VARCHAR(50), -- mask, polygon, bbox
    mask_path VARCHAR(500),
    vectors JSONB, -- çŸ¢é‡åŒ–çš„è½®å»“æ•°æ®
    
    attributes JSONB, -- è£‚çº¹å±æ€§
    
    annotator_id BIGINT,
    is_verified BOOLEAN DEFAULT FALSE,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (image_id) REFERENCES image(id) ON DELETE CASCADE,
    FOREIGN KEY (annotator_id) REFERENCES sys_user(id)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_dataset_status ON dataset(status);
CREATE INDEX idx_dataset_created_by ON dataset(created_by);
CREATE INDEX idx_image_dataset ON image(dataset_id);
CREATE INDEX idx_image_split ON image(split);
CREATE INDEX idx_annotation_image ON annotation(image_id);
```

#### 5.2.3 æ¨ç†ç›¸å…³è¡¨

```sql
-- æ£€æµ‹ä»»åŠ¡è¡¨
CREATE TABLE detection_job (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    
    image_url VARCHAR(500) NOT NULL,
    image_name VARCHAR(255),
    
    model_version VARCHAR(50),
    config JSONB, -- æ¨ç†é…ç½®
    
    status VARCHAR(20) DEFAULT 'pending', -- pending, running, completed, failed
    progress NUMERIC(5,2) DEFAULT 0, -- 0-100
    
    result_id BIGINT,
    error_message TEXT,
    
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (user_id) REFERENCES sys_user(id)
);

-- æ£€æµ‹ç»“æœè¡¨
CREATE TABLE detection_result (
    id BIGSERIAL PRIMARY KEY,
    job_id BIGINT NOT NULL,
    image_id BIGINT,
    model_id BIGINT,
    
    mask_url VARCHAR(500),
    overlay_url VARCHAR(500),
    heatmap_url VARCHAR(500),
    
    vectors JSONB, -- çŸ¢é‡åŒ–ç»“æœ
    attributes JSONB, -- è£‚çº¹å±æ€§æ•°ç»„
    statistics JSONB, -- ç»Ÿè®¡ä¿¡æ¯
    
    confidence NUMERIC(5,4), -- 0-1
    processing_time NUMERIC(10,2), -- ç§’
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES detection_job(id) ON DELETE CASCADE
);

-- æ¨¡å‹è¡¨
CREATE TABLE model (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    version VARCHAR(50) NOT NULL,
    architecture VARCHAR(100), -- unet, unet++, deeplabv3+
    framework VARCHAR(50), -- pytorch, tensorflow
    
    model_path VARCHAR(500),
    config JSONB,
    
    metrics JSONB, -- IoU, Recall, Precisionç­‰
    
    training_dataset_id BIGINT,
    
    is_active BOOLEAN DEFAULT FALSE,
    is_public BOOLEAN DEFAULT TRUE,
    
    created_by BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE(name, version),
    FOREIGN KEY (training_dataset_id) REFERENCES dataset(id),
    FOREIGN KEY (created_by) REFERENCES sys_user(id)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_job_user ON detection_job(user_id);
CREATE INDEX idx_job_status ON detection_job(status);
CREATE INDEX idx_job_created ON detection_job(created_at DESC);
CREATE INDEX idx_result_job ON detection_result(job_id);
CREATE INDEX idx_result_confidence ON detection_result(confidence);
CREATE INDEX idx_model_active ON model(is_active);
```

#### 5.2.4 æŠ¥å‘Šè¡¨

```sql
-- æŠ¥å‘Šè¡¨
CREATE TABLE report (
    id BIGSERIAL PRIMARY KEY,
    result_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,
    
    report_type VARCHAR(20), -- pdf, excel, word
    template_name VARCHAR(100),
    
    file_url VARCHAR(500),
    file_size BIGINT,
    
    status VARCHAR(20) DEFAULT 'generating', -- generating, ready, failed
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (result_id) REFERENCES detection_result(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES sys_user(id)
);

-- æŠ¥å‘Šæ¨¡æ¿è¡¨
CREATE TABLE report_template (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    template_type VARCHAR(20), -- pdf, excel
    template_content TEXT, -- HTMLæˆ–æ¨¡æ¿å®šä¹‰
    
    is_default BOOLEAN DEFAULT FALSE,
    is_public BOOLEAN DEFAULT TRUE,
    
    created_by BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (created_by) REFERENCES sys_user(id)
);

CREATE INDEX idx_report_result ON report(result_id);
CREATE INDEX idx_report_user ON report(user_id);
CREATE INDEX idx_report_status ON report(status);
```

### 5.3 æ•°æ®ç‰ˆæœ¬ç®¡ç†

```sql
-- æ•°æ®é›†ç‰ˆæœ¬è¡¨
CREATE TABLE dataset_version (
    id BIGSERIAL PRIMARY KEY,
    dataset_id BIGINT NOT NULL,
    version_number VARCHAR(50) NOT NULL,
    
    changes JSONB, -- å˜æ›´è®°å½•ï¼šadded, modified, deleted
    commit_message TEXT,
    
    parent_version_id BIGINT,
    
    created_by BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE(dataset_id, version_number),
    FOREIGN KEY (dataset_id) REFERENCES dataset(id) ON DELETE CASCADE,
    FOREIGN KEY (parent_version_id) REFERENCES dataset_version(id),
    FOREIGN KEY (created_by) REFERENCES sys_user(id)
);

-- æ¨¡å‹ç‰ˆæœ¬è¡¨
CREATE TABLE model_version (
    id BIGSERIAL PRIMARY KEY,
    model_id BIGINT NOT NULL,
    version_number VARCHAR(50) NOT NULL,
    
    training_config JSONB,
    metrics JSONB,
    artifacts JSONB, -- æ¨¡å‹æ–‡ä»¶ã€é…ç½®æ–‡ä»¶ç­‰è·¯å¾„
    
    parent_version_id BIGINT,
    commit_message TEXT,
    
    created_by BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE(model_id, version_number),
    FOREIGN KEY (model_id) REFERENCES model(id) ON DELETE CASCADE,
    FOREIGN KEY (parent_version_id) REFERENCES model_version(id),
    FOREIGN KEY (created_by) REFERENCES sys_user(id)
);
```

### 5.4 å®¡è®¡ä¸æ—¥å¿—è¡¨

```sql
-- æ“ä½œæ—¥å¿—è¡¨
CREATE TABLE operation_log (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    username VARCHAR(50),
    
    operation VARCHAR(100), -- æ“ä½œç±»å‹
    method VARCHAR(100), -- æ–¹æ³•å
    params TEXT, -- è¯·æ±‚å‚æ•°
    
    ip_address VARCHAR(50),
    user_agent TEXT,
    
    status VARCHAR(20), -- success, failed
    error_message TEXT,
    
    execution_time INT, -- æ¯«ç§’
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç™»å½•æ—¥å¿—è¡¨
CREATE TABLE login_log (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    username VARCHAR(50),
    
    login_type VARCHAR(20), -- password, oauth, sms
    ip_address VARCHAR(50),
    location VARCHAR(100),
    device VARCHAR(100),
    
    status VARCHAR(20), -- success, failed
    message TEXT,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç³»ç»Ÿç›‘æ§è¡¨
CREATE TABLE system_metrics (
    id BIGSERIAL PRIMARY KEY,
    service_name VARCHAR(50),
    
    cpu_usage NUMERIC(5,2),
    memory_usage NUMERIC(5,2),
    disk_usage NUMERIC(5,2),
    
    request_count INT,
    error_count INT,
    avg_response_time INT,
    
    recorded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_operation_log_user ON operation_log(user_id);
CREATE INDEX idx_operation_log_created ON operation_log(created_at DESC);
CREATE INDEX idx_login_log_user ON login_log(user_id);
CREATE INDEX idx_login_log_created ON login_log(created_at DESC);
CREATE INDEX idx_metrics_service ON system_metrics(service_name);
CREATE INDEX idx_metrics_recorded ON system_metrics(recorded_at DESC);
```

---

## 6. æ¥å£è®¾è®¡

### 6.1 RESTful API è®¾è®¡è§„èŒƒ

#### 6.1.1 URLè®¾è®¡

```
åŸºç¡€è·¯å¾„: /api/v1

èµ„æºå‘½å: ä½¿ç”¨åè¯å¤æ•°

ç¤ºä¾‹:
GET    /api/v1/datasets              # è·å–æ•°æ®é›†åˆ—è¡¨
POST   /api/v1/datasets              # åˆ›å»ºæ•°æ®é›†
GET    /api/v1/datasets/{id}         # è·å–æ•°æ®é›†è¯¦æƒ…
PUT    /api/v1/datasets/{id}         # æ›´æ–°æ•°æ®é›†
DELETE /api/v1/datasets/{id}         # åˆ é™¤æ•°æ®é›†

GET    /api/v1/datasets/{id}/images  # è·å–æ•°æ®é›†çš„å›¾åƒåˆ—è¡¨
POST   /api/v1/inference/jobs        # åˆ›å»ºæ¨ç†ä»»åŠ¡
GET    /api/v1/inference/jobs/{id}   # è·å–ä»»åŠ¡çŠ¶æ€
```

#### 6.1.2 HTTPçŠ¶æ€ç 

```
200 OK: è¯·æ±‚æˆåŠŸ
201 Created: åˆ›å»ºæˆåŠŸ
204 No Content: åˆ é™¤æˆåŠŸ
400 Bad Request: è¯·æ±‚å‚æ•°é”™è¯¯
401 Unauthorized: æœªè®¤è¯
403 Forbidden: æ— æƒé™
404 Not Found: èµ„æºä¸å­˜åœ¨
409 Conflict: èµ„æºå†²çª
500 Internal Server Error: æœåŠ¡å™¨é”™è¯¯
503 Service Unavailable: æœåŠ¡ä¸å¯ç”¨
```

#### 6.1.3 ç»Ÿä¸€å“åº”æ ¼å¼

```json
{
  "code": 200,
  "message": "success",
  "data": {
    // å…·ä½“æ•°æ®
  },
  "timestamp": 1699267200000
}

// åˆ†é¡µå“åº”
{
  "code": 200,
  "message": "success",
  "data": {
    "records": [
      // æ•°æ®åˆ—è¡¨
    ],
    "total": 100,
    "page": 1,
    "size": 10,
    "pages": 10
  },
  "timestamp": 1699267200000
}

// é”™è¯¯å“åº”
{
  "code": 400,
  "message": "å‚æ•°é”™è¯¯",
  "data": null,
  "timestamp": 1699267200000,
  "error": {
    "field": "username",
    "reason": "ç”¨æˆ·åä¸èƒ½ä¸ºç©º"
  }
}
```

### 6.2 æ ¸å¿ƒæ¥å£åˆ—è¡¨

#### 6.2.1 è®¤è¯ç›¸å…³æ¥å£

```yaml
# ç”¨æˆ·æ³¨å†Œ
POST /api/v1/auth/register
Request:
  username: string (required)
  password: string (required)
  email: string (required)
  phone: string
Response:
  userId: long
  username: string

# ç”¨æˆ·ç™»å½•
POST /api/v1/auth/login
Request:
  username: string
  password: string
Response:
  accessToken: string
  refreshToken: string
  expiresIn: int
  tokenType: string
  userInfo: object

# åˆ·æ–°ä»¤ç‰Œ
POST /api/v1/auth/refresh
Request:
  refreshToken: string
Response:
  accessToken: string
  expiresIn: int

# ç™»å‡º
POST /api/v1/auth/logout
Headers:
  Authorization: Bearer {token}
Response:
  message: "ç™»å‡ºæˆåŠŸ"
```

#### 6.2.2 æ•°æ®é›†æ¥å£

```yaml
# åˆ›å»ºæ•°æ®é›†
POST /api/v1/datasets
Request:
  name: string
  description: string
  source: string (rdd2022, crack500, upload)
  format: string (coco, voc, yolo)
  config: object
Response:
  datasetId: long
  status: string

# ä¸Šä¼ æ•°æ®é›†æ–‡ä»¶
POST /api/v1/datasets/upload
Request:
  file: multipart/form-data
  datasetName: string
Response:
  uploadUrl: string

# è·å–æ•°æ®é›†åˆ—è¡¨
GET /api/v1/datasets?page=1&size=10&status=ready
Response:
  records: array
  total: int
  page: int
  size: int

# è·å–æ•°æ®é›†è¯¦æƒ…
GET /api/v1/datasets/{id}
Response:
  id: long
  name: string
  totalImages: int
  trainCount: int
  valCount: int
  testCount: int
  storagePath: string
  metadata: object

# æ•°æ®é¢„å¤„ç†
POST /api/v1/datasets/{id}/preprocess
Request:
  splitRatio: [0.7, 0.15, 0.15]
  augmentation: boolean
  augmentConfig: object
Response:
  jobId: string
  status: string
```

#### 6.2.3 æ¨ç†æ¥å£

```yaml
# åˆ›å»ºæ¨ç†ä»»åŠ¡
POST /api/v1/inference/jobs
Request:
  imageUrl: string
  æˆ–
  file: multipart/form-data
  ---
  modelVersion: string
  threshold: float (0-1)
  minArea: int
  returnMask: boolean
  returnVectors: boolean
  returnAttributes: boolean
Response:
  jobId: long
  status: string
  createdAt: datetime

# è·å–ä»»åŠ¡çŠ¶æ€
GET /api/v1/inference/jobs/{jobId}
Response:
  jobId: long
  status: string (pending, running, completed, failed)
  progress: float (0-100)
  result: object (if completed)
  errorMessage: string (if failed)

# æ‰¹é‡æ¨ç†
POST /api/v1/inference/batch
Request:
  imageUrls: array[string]
  modelVersion: string
  config: object
Response:
  batchId: string
  totalJobs: int
  jobIds: array[long]

# è·å–ä»»åŠ¡åˆ—è¡¨
GET /api/v1/inference/jobs?page=1&size=10&status=completed
Response:
  records: array
  total: int
```

#### 6.2.4 å¯è§†åŒ–æ¥å£

```yaml
# ç”Ÿæˆå åŠ å›¾åƒ
POST /api/v1/visualization/overlay
Request:
  resultId: long
  config:
    alpha: float (0-1)
    maskColor: string (hex)
    drawContours: boolean
    drawAnnotations: boolean
Response:
  overlayUrl: string

# ç”Ÿæˆçƒ­åŠ›å›¾
POST /api/v1/visualization/heatmap
Request:
  resultId: long
  config:
    colorMap: string (jet, hot, cool)
Response:
  heatmapUrl: string

# è·å–ç»Ÿè®¡æ•°æ®
GET /api/v1/visualization/statistics/{resultId}
Response:
  totalCracks: int
  totalLength: float
  avgWidth: float
  maxWidth: float
  typeDistribution: object
  severityDistribution: object
```

#### 6.2.5 æŠ¥å‘Šæ¥å£

```yaml
# ç”ŸæˆPDFæŠ¥å‘Š
POST /api/v1/reports/pdf
Request:
  resultId: long
  templateName: string
Response:
  reportId: long
  reportUrl: string
  status: string

# ç”ŸæˆExcelæŠ¥å‘Š
POST /api/v1/reports/excel
Request:
  resultId: long
Response:
  reportId: long
  reportUrl: string

# ä¸‹è½½æŠ¥å‘Š
GET /api/v1/reports/{reportId}/download
Response:
  æ–‡ä»¶æµ
```

### 6.3 WebSocketæ¥å£ï¼ˆå®æ—¶æ¨é€ï¼‰

```yaml
# è¿æ¥WebSocket
ws://localhost:8080/ws/inference?token={jwt_token}

# è®¢é˜…æ¨ç†ä»»åŠ¡è¿›åº¦
Subscribe: /topic/inference/{jobId}
Message:
  jobId: long
  status: string
  progress: float
  message: string

# è®¢é˜…ç³»ç»Ÿé€šçŸ¥
Subscribe: /topic/notifications
Message:
  type: string
  title: string
  content: string
  timestamp: datetime
```

---

## 7. ç³»ç»Ÿäº¤äº’æµç¨‹

### 7.1 ç”¨æˆ·æ³¨å†Œç™»å½•æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant G as Gateway
    participant A as Auth Service
    participant DB as PostgreSQL
    participant R as Redis
    
    U->>F: è¾“å…¥ç”¨æˆ·åå¯†ç 
    F->>G: POST /api/v1/auth/login
    G->>A: è½¬å‘è¯·æ±‚
    A->>DB: æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯
    DB-->>A: è¿”å›ç”¨æˆ·æ•°æ®
    A->>A: éªŒè¯å¯†ç 
    A->>A: ç”ŸæˆJWTä»¤ç‰Œ
    A->>R: ç¼“å­˜ä»¤ç‰Œ
    A-->>G: è¿”å›ä»¤ç‰Œå’Œç”¨æˆ·ä¿¡æ¯
    G-->>F: è¿”å›å“åº”
    F->>F: ä¿å­˜tokenåˆ°localStorage
    F-->>U: è·³è½¬åˆ°é¦–é¡µ
```

### 7.2 æ•°æ®é›†å¯¼å…¥æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant G as Gateway
    participant D as Dataset Service
    participant M as MinIO
    participant MQ as RabbitMQ
    participant DB as PostgreSQL
    
    U->>F: ä¸Šä¼ æ•°æ®é›†æ–‡ä»¶
    F->>G: POST /api/v1/datasets/upload
    G->>D: è½¬å‘è¯·æ±‚
    D->>DB: åˆ›å»ºæ•°æ®é›†è®°å½•
    D->>M: ä¸Šä¼ æ–‡ä»¶åˆ°å¯¹è±¡å­˜å‚¨
    M-->>D: è¿”å›å­˜å‚¨è·¯å¾„
    D->>D: è§£ææ•°æ®é›†æ ¼å¼
    D->>DB: ä¿å­˜å›¾åƒå…ƒæ•°æ®
    D->>MQ: å‘é€é¢„å¤„ç†ä»»åŠ¡
    D-->>G: è¿”å›æ•°æ®é›†ID
    G-->>F: è¿”å›å“åº”
    F-->>U: æ˜¾ç¤ºå¯¼å…¥æˆåŠŸ
    
    Note over MQ,D: å¼‚æ­¥é¢„å¤„ç†
    MQ->>D: æ¶ˆè´¹é¢„å¤„ç†ä»»åŠ¡
    D->>D: æ•°æ®å¢å¼ºã€åˆ’åˆ†
    D->>DB: æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
```

### 7.3 è£‚çº¹æ£€æµ‹å®Œæ•´æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant G as Gateway
    participant I as Inference Service
    participant P as Python Service
    participant M as MinIO
    participant DB as PostgreSQL
    participant R as Redis
    participant WS as WebSocket
    
    U->>F: ä¸Šä¼ é“è·¯å›¾åƒ
    F->>G: POST /api/v1/inference/jobs
    G->>I: åˆ›å»ºæ¨ç†ä»»åŠ¡
    I->>DB: ä¿å­˜ä»»åŠ¡è®°å½•
    I->>M: ä¸Šä¼ å›¾åƒåˆ°MinIO
    M-->>I: è¿”å›å›¾åƒURL
    I-->>G: è¿”å›ä»»åŠ¡ID
    G-->>F: è¿”å›jobId
    F-->>U: æ˜¾ç¤º"å¤„ç†ä¸­"
    
    Note over I,P: å¼‚æ­¥æ¨ç†
    I->>I: å¼‚æ­¥è°ƒç”¨æ¨ç†
    I->>M: ä¸‹è½½å›¾åƒ
    I->>P: POST /detect (Feignè°ƒç”¨)
    P->>P: åŠ è½½æ¨¡å‹
    P->>P: å›¾åƒé¢„å¤„ç†
    P->>P: æ¨¡å‹æ¨ç† (GPU)
    P->>P: åå¤„ç†ã€ç‰¹å¾æå–
    P->>M: ä¿å­˜ç»“æœå›¾åƒ
    P-->>I: è¿”å›æ£€æµ‹ç»“æœ
    I->>DB: ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
    I->>R: ç¼“å­˜ç»“æœ
    I->>WS: æ¨é€å®Œæˆé€šçŸ¥
    WS-->>F: å®æ—¶æ¨é€
    F-->>U: æ˜¾ç¤ºæ£€æµ‹ç»“æœ
    
    U->>F: æŸ¥çœ‹è¯¦ç»†ç»“æœ
    F->>G: GET /api/v1/inference/jobs/{jobId}
    G->>I: è·å–ç»“æœ
    I->>R: å…ˆæŸ¥ç¼“å­˜
    alt ç¼“å­˜å‘½ä¸­
        R-->>I: è¿”å›ç¼“å­˜ç»“æœ
    else ç¼“å­˜æœªå‘½ä¸­
        I->>DB: æŸ¥è¯¢æ•°æ®åº“
        DB-->>I: è¿”å›ç»“æœ
        I->>R: æ›´æ–°ç¼“å­˜
    end
    I-->>G: è¿”å›å®Œæ•´ç»“æœ
    G-->>F: è¿”å›æ•°æ®
    F->>F: æ¸²æŸ“å¯è§†åŒ–
    F-->>U: æ˜¾ç¤ºå åŠ å›¾åƒã€ç»Ÿè®¡ä¿¡æ¯
```

### 7.4 æŠ¥å‘Šç”Ÿæˆæµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant R as Report Service
    participant V as Visual Service
    participant M as MinIO
    participant DB as PostgreSQL
    
    U->>F: ç‚¹å‡»"ç”ŸæˆæŠ¥å‘Š"
    F->>R: POST /api/v1/reports/pdf
    R->>DB: æŸ¥è¯¢æ£€æµ‹ç»“æœ
    R->>V: è·å–ç»Ÿè®¡æ•°æ®
    V-->>R: è¿”å›ç»Ÿè®¡ä¿¡æ¯
    R->>M: ä¸‹è½½å›¾åƒ
    R->>R: ç”ŸæˆPDFæ–‡æ¡£
    R->>M: ä¸Šä¼ PDFåˆ°MinIO
    M-->>R: è¿”å›PDF URL
    R->>DB: ä¿å­˜æŠ¥å‘Šè®°å½•
    R-->>F: è¿”å›æŠ¥å‘ŠURL
    F->>F: æ˜¾ç¤ºä¸‹è½½é“¾æ¥
    U->>F: ç‚¹å‡»ä¸‹è½½
    F->>M: ä¸‹è½½PDFæ–‡ä»¶
    M-->>F: è¿”å›æ–‡ä»¶æµ
    F-->>U: æµè§ˆå™¨ä¸‹è½½
```

### 7.5 æ‰¹é‡æ£€æµ‹æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant I as Inference Service
    participant MQ as RabbitMQ
    participant P as Python Service
    participant DB as PostgreSQL
    
    U->>F: é€‰æ‹©å¤šå¼ å›¾åƒ
    F->>I: POST /api/v1/inference/batch
    I->>I: åˆ›å»ºæ‰¹é‡ä»»åŠ¡
    loop æ¯å¼ å›¾åƒ
        I->>DB: åˆ›å»ºä»»åŠ¡è®°å½•
        I->>MQ: å‘é€åˆ°é˜Ÿåˆ—
    end
    I-->>F: è¿”å›æ‰¹æ¬¡IDå’Œä»»åŠ¡åˆ—è¡¨
    F-->>U: æ˜¾ç¤ºæ‰¹æ¬¡è¿›åº¦
    
    Note over MQ,P: å¹¶è¡Œå¤„ç†
    par ä»»åŠ¡1
        MQ->>P: Worker1 æ¶ˆè´¹ä»»åŠ¡
        P->>P: æ‰§è¡Œæ¨ç†
        P->>DB: æ›´æ–°ç»“æœ
    and ä»»åŠ¡2
        MQ->>P: Worker2 æ¶ˆè´¹ä»»åŠ¡
        P->>P: æ‰§è¡Œæ¨ç†
        P->>DB: æ›´æ–°ç»“æœ
    and ä»»åŠ¡3
        MQ->>P: Worker3 æ¶ˆè´¹ä»»åŠ¡
        P->>P: æ‰§è¡Œæ¨ç†
        P->>DB: æ›´æ–°ç»“æœ
    end
    
    Note over F,I: è½®è¯¢æˆ–WebSocketæ›´æ–°è¿›åº¦
    loop æ£€æŸ¥è¿›åº¦
        F->>I: GET /api/v1/inference/batch/{batchId}
        I->>DB: æŸ¥è¯¢æ‰¹æ¬¡çŠ¶æ€
        I-->>F: è¿”å›è¿›åº¦
        F->>F: æ›´æ–°è¿›åº¦æ¡
    end
    
    I->>F: WebSocketæ¨é€å®Œæˆ
    F-->>U: æ˜¾ç¤º"å…¨éƒ¨å®Œæˆ"
```

---

## 8. éƒ¨ç½²æ–¹æ¡ˆ

### 8.1 å¼€å‘ç¯å¢ƒéƒ¨ç½²ï¼ˆDocker Composeï¼‰

#### 8.1.1 docker-compose.yml

```yaml
version: '3.8'

services:
  # ==================== åŸºç¡€è®¾æ–½ ====================
  
  # PostgreSQL
  postgres:
    image: postgres:15-alpine
    container_name: crack-postgres
    environment:
      POSTGRES_DB: crack_detection
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - crack-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    container_name: crack-redis
    command: redis-server --requirepass redis123
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - crack-network

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: crack-rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - crack-network

  # MinIO
  minio:
    image: minio/minio:latest
    container_name: crack-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin123456
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - crack-network

  # Nacos (æœåŠ¡æ³¨å†Œä¸é…ç½®ä¸­å¿ƒ)
  nacos:
    image: nacos/nacos-server:v2.3.0
    container_name: crack-nacos
    environment:
      MODE: standalone
      SPRING_DATASOURCE_PLATFORM: mysql
      MYSQL_SERVICE_HOST: mysql
      MYSQL_SERVICE_DB_NAME: nacos
      MYSQL_SERVICE_USER: root
      MYSQL_SERVICE_PASSWORD: root123
    ports:
      - "8848:8848"
      - "9848:9848"
    volumes:
      - nacos_data:/home/nacos/data
    networks:
      - crack-network
    depends_on:
      - mysql

  # MySQL (for Nacos)
  mysql:
    image: mysql:8.0
    container_name: crack-mysql
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: nacos
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - crack-network

  # ==================== Javaå¾®æœåŠ¡ ====================
  
  # APIç½‘å…³
  gateway:
    build:
      context: ./cloud-gateway
      dockerfile: Dockerfile
    container_name: cloud-gateway
    environment:
      SPRING_PROFILES_ACTIVE: docker
      NACOS_SERVER_ADDR: nacos:8848
      REDIS_HOST: redis
      REDIS_PASSWORD: redis123
    ports:
      - "8080:8080"
    depends_on:
      - nacos
      - redis
    networks:
      - crack-network

  # è®¤è¯æœåŠ¡
  auth-service:
    build:
      context: ./cloud-auth
      dockerfile: Dockerfile
    container_name: cloud-auth
    environment:
      SPRING_PROFILES_ACTIVE: docker
      NACOS_SERVER_ADDR: nacos:8848
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: crack_detection
      DB_USER: admin
      DB_PASSWORD: admin123
      REDIS_HOST: redis
      REDIS_PASSWORD: redis123
    ports:
      - "8081:8081"
    depends_on:
      - nacos
      - postgres
      - redis
    networks:
      - crack-network

  # æ•°æ®é›†æœåŠ¡
  dataset-service:
    build:
      context: ./cloud-dataset
      dockerfile: Dockerfile
    container_name: cloud-dataset
    environment:
      SPRING_PROFILES_ACTIVE: docker
      NACOS_SERVER_ADDR: nacos:8848
      DB_HOST: postgres
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: admin
      MINIO_SECRET_KEY: admin123456
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_USER: admin
      RABBITMQ_PASSWORD: admin123
    ports:
      - "8082:8082"
    volumes:
      - ./data:/app/data
    depends_on:
      - nacos
      - postgres
      - minio
      - rabbitmq
    networks:
      - crack-network

  # æ¨ç†æœåŠ¡
  inference-service:
    build:
      context: ./cloud-inference
      dockerfile: Dockerfile
    container_name: cloud-inference
    environment:
      SPRING_PROFILES_ACTIVE: docker
      NACOS_SERVER_ADDR: nacos:8848
      DB_HOST: postgres
      REDIS_HOST: redis
      PYTHON_INFERENCE_URL: http://python-inference:8090
    ports:
      - "8083:8083"
    depends_on:
      - nacos
      - postgres
      - redis
      - python-inference
    networks:
      - crack-network

  # å¯è§†åŒ–æœåŠ¡
  visual-service:
    build:
      context: ./cloud-visual
      dockerfile: Dockerfile
    container_name: cloud-visual
    environment:
      SPRING_PROFILES_ACTIVE: docker
      NACOS_SERVER_ADDR: nacos:8848
      DB_HOST: postgres
      MINIO_ENDPOINT: minio:9000
    ports:
      - "8084:8084"
    depends_on:
      - nacos
      - postgres
      - minio
    networks:
      - crack-network

  # æŠ¥å‘ŠæœåŠ¡
  report-service:
    build:
      context: ./cloud-report
      dockerfile: Dockerfile
    container_name: cloud-report
    environment:
      SPRING_PROFILES_ACTIVE: docker
      NACOS_SERVER_ADDR: nacos:8848
      DB_HOST: postgres
      MINIO_ENDPOINT: minio:9000
    ports:
      - "8085:8085"
    depends_on:
      - nacos
      - postgres
      - minio
    networks:
      - crack-network

  # ==================== Pythonæ¨ç†æœåŠ¡ ====================
  
  python-inference:
    build:
      context: ./python-inference
      dockerfile: Dockerfile
    container_name: python-inference
    environment:
      MODEL_PATH: /models
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: admin
      MINIO_SECRET_KEY: admin123456
      REDIS_HOST: redis
      REDIS_PASSWORD: redis123
    ports:
      - "8090:8090"
    volumes:
      - ./data/models:/models
    # GPUæ”¯æŒï¼ˆéœ€è¦nvidia-dockerï¼‰
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    depends_on:
      - minio
      - redis
    networks:
      - crack-network

  # ==================== å‰ç«¯ ====================
  
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: crack-frontend
    environment:
      VITE_API_BASE_URL: http://localhost:8080/api
      VITE_WS_URL: ws://localhost:8080/ws
    ports:
      - "3000:3000"
    depends_on:
      - gateway
    networks:
      - crack-network

  # ==================== ç›‘æ§ ====================
  
  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: crack-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - crack-network

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: crack-grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus
    networks:
      - crack-network

networks:
  crack-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  rabbitmq_data:
  minio_data:
  nacos_data:
  mysql_data:
  prometheus_data:
  grafana_data:
```

#### 8.1.2 æœåŠ¡Dockerfileç¤ºä¾‹

**JavaæœåŠ¡Dockerfile:**

```dockerfile
# cloud-inference/Dockerfile
FROM maven:3.9-eclipse-temurin-17 AS build
WORKDIR /app

# å¤åˆ¶çˆ¶POMå’Œå­æ¨¡å—
COPY pom.xml .
COPY cloud-common ./cloud-common
COPY cloud-inference ./cloud-inference

# æ„å»º
RUN mvn clean package -DskipTests -pl cloud-inference -am

# è¿è¡Œé˜¶æ®µ
FROM eclipse-temurin:17-jre-alpine
WORKDIR /app

# å¤åˆ¶jaråŒ…
COPY --from=build /app/cloud-inference/target/*.jar app.jar

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD wget --quiet --tries=1 --spider http://localhost:8083/actuator/health || exit 1

# å¯åŠ¨å‚æ•°
ENV JAVA_OPTS="-Xms512m -Xmx1024m -XX:+UseG1GC"

EXPOSE 8083

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

**PythonæœåŠ¡Dockerfile:**

```dockerfile
# python-inference/Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY app ./app

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:8090/health || exit 1

EXPOSE 8090

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8090"]
```

### 8.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆKubernetesï¼‰

#### 8.2.1 Namespaceé…ç½®

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: crack-detection
  labels:
    name: crack-detection
    env: production
```

#### 8.2.2 ConfigMapé…ç½®

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: crack-detection
data:
  # æ•°æ®åº“é…ç½®
  DB_HOST: "postgres-service"
  DB_PORT: "5432"
  DB_NAME: "crack_detection"
  
  # Redisé…ç½®
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  
  # MinIOé…ç½®
  MINIO_ENDPOINT: "minio-service:9000"
  
  # RabbitMQé…ç½®
  RABBITMQ_HOST: "rabbitmq-service"
  RABBITMQ_PORT: "5672"
  
  # Nacosé…ç½®
  NACOS_SERVER_ADDR: "nacos-service:8848"
  
  # Pythonæ¨ç†æœåŠ¡é…ç½®
  PYTHON_INFERENCE_URL: "http://python-inference-service:8090"
```

#### 8.2.3 Secreté…ç½®

```yaml
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: crack-detection
type: Opaque
stringData:
  DB_USER: "admin"
  DB_PASSWORD: "your_secure_password"
  REDIS_PASSWORD: "your_redis_password"
  MINIO_ACCESS_KEY: "admin"
  MINIO_SECRET_KEY: "your_minio_secret_key"
  RABBITMQ_USER: "admin"
  RABBITMQ_PASSWORD: "your_rabbitmq_password"
  JWT_SECRET_KEY: "your_jwt_secret_key_min_32_chars"
```

#### 8.2.4 æ¨ç†æœåŠ¡Deployment

```yaml
# k8s/services/inference-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-service
  namespace: crack-detection
  labels:
    app: inference-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: inference-service
  template:
    metadata:
      labels:
        app: inference-service
    spec:
      containers:
      - name: inference-service
        image: your-registry/cloud-inference:1.0.0
        imagePullPolicy: Always
        ports:
        - containerPort: 8083
          name: http
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "k8s"
        - name: DB_HOST
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: DB_HOST
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: DB_USER
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: DB_PASSWORD
        - name: REDIS_HOST
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: REDIS_HOST
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: REDIS_PASSWORD
        - name: PYTHON_INFERENCE_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: PYTHON_INFERENCE_URL
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8083
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8083
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: inference-service
  namespace: crack-detection
spec:
  selector:
    app: inference-service
  ports:
  - protocol: TCP
    port: 8083
    targetPort: 8083
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: inference-service-hpa
  namespace: crack-detection
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: inference-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### 8.2.5 Pythonæ¨ç†æœåŠ¡Deployment

```yaml
# k8s/services/python-inference-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: python-inference
  namespace: crack-detection
spec:
  replicas: 2
  selector:
    matchLabels:
      app: python-inference
  template:
    metadata:
      labels:
        app: python-inference
    spec:
      # GPUèŠ‚ç‚¹é€‰æ‹©å™¨
      nodeSelector:
        gpu: "true"
      containers:
      - name: python-inference
        image: your-registry/python-inference:1.0.0
        ports:
        - containerPort: 8090
        env:
        - name: MODEL_PATH
          value: "/models"
        - name: MINIO_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: MINIO_ENDPOINT
        - name: MINIO_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: MINIO_ACCESS_KEY
        - name: MINIO_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: MINIO_SECRET_KEY
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "4"
            nvidia.com/gpu: 1
        volumeMounts:
        - name: model-storage
          mountPath: /models
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: python-inference-service
  namespace: crack-detection
spec:
  selector:
    app: python-inference
  ports:
  - protocol: TCP
    port: 8090
    targetPort: 8090
  type: ClusterIP
```

#### 8.2.6 Ingressé…ç½®

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: crack-detection-ingress
  namespace: crack-detection
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - api.crackdetection.com
    secretName: crack-detection-tls
  rules:
  - host: api.crackdetection.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: gateway-service
            port:
              number: 8080
```

### 8.3 CI/CDæµç¨‹

#### 8.3.1 GitLab CIé…ç½®

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

variables:
  MAVEN_OPTS: "-Dmaven.repo.local=.m2/repository"
  DOCKER_REGISTRY: "your-registry.com"
  K8S_NAMESPACE: "crack-detection"

# æµ‹è¯•é˜¶æ®µ
test:java:
  stage: test
  image: maven:3.9-eclipse-temurin-17
  script:
    - mvn clean test
  artifacts:
    reports:
      junit: "**/target/surefire-reports/TEST-*.xml"
  cache:
    paths:
      - .m2/repository
  only:
    - merge_requests
    - main

test:python:
  stage: test
  image: python:3.10
  script:
    - cd python-inference
    - pip install -r requirements.txt
    - pytest tests/
  only:
    - merge_requests
    - main

# æ„å»ºé˜¶æ®µ
build:java:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $DOCKER_REGISTRY
    # æ„å»ºå„ä¸ªå¾®æœåŠ¡
    - docker build -t $DOCKER_REGISTRY/cloud-gateway:$CI_COMMIT_SHA ./cloud-gateway
    - docker build -t $DOCKER_REGISTRY/cloud-auth:$CI_COMMIT_SHA ./cloud-auth
    - docker build -t $DOCKER_REGISTRY/cloud-inference:$CI_COMMIT_SHA ./cloud-inference
    # æ¨é€é•œåƒ
    - docker push $DOCKER_REGISTRY/cloud-gateway:$CI_COMMIT_SHA
    - docker push $DOCKER_REGISTRY/cloud-auth:$CI_COMMIT_SHA
    - docker push $DOCKER_REGISTRY/cloud-inference:$CI_COMMIT_SHA
  only:
    - main

build:python:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $DOCKER_REGISTRY
    - docker build -t $DOCKER_REGISTRY/python-inference:$CI_COMMIT_SHA ./python-inference
    - docker push $DOCKER_REGISTRY/python-inference:$CI_COMMIT_SHA
  only:
    - main

# éƒ¨ç½²é˜¶æ®µ
deploy:dev:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context dev
    - kubectl set image deployment/inference-service 
        inference-service=$DOCKER_REGISTRY/cloud-inference:$CI_COMMIT_SHA 
        -n $K8S_NAMESPACE
    - kubectl rollout status deployment/inference-service -n $K8S_NAMESPACE
  environment:
    name: development
  only:
    - main

deploy:prod:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context prod
    - kubectl set image deployment/inference-service 
        inference-service=$DOCKER_REGISTRY/cloud-inference:$CI_COMMIT_SHA 
        -n $K8S_NAMESPACE
    - kubectl rollout status deployment/inference-service -n $K8S_NAMESPACE
  environment:
    name: production
  when: manual
  only:
    - main
```

---

## 9. æ€§èƒ½ä¼˜åŒ–

### 9.1 æ•°æ®åº“ä¼˜åŒ–

#### 9.1.1 ç´¢å¼•ä¼˜åŒ–

```sql
-- å¤åˆç´¢å¼•ï¼ˆè¦†ç›–å¸¸ç”¨æŸ¥è¯¢ï¼‰
CREATE INDEX idx_job_user_status_created ON detection_job(user_id, status, created_at DESC);

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•éœ€è¦çš„æ•°æ®ï¼‰
CREATE INDEX idx_job_completed ON detection_job(user_id, created_at DESC) 
WHERE status = 'completed';

-- JSONå­—æ®µç´¢å¼•
CREATE INDEX idx_result_attributes_type ON detection_result 
USING GIN ((attributes->'cracks'));

-- è¡¨åˆ†åŒºï¼ˆæŒ‰æ—¶é—´åˆ†åŒºï¼‰
CREATE TABLE detection_job_2024_01 PARTITION OF detection_job
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

#### 9.1.2 æŸ¥è¯¢ä¼˜åŒ–

```java
// åˆ†é¡µæŸ¥è¯¢ä¼˜åŒ–ï¼ˆä½¿ç”¨æ¸¸æ ‡ï¼‰
@Mapper
public interface DetectionJobMapper extends BaseMapper<DetectionJob> {
    
    @Select("""
        SELECT * FROM detection_job 
        WHERE user_id = #{userId} 
        AND id > #{lastId} 
        ORDER BY id 
        LIMIT #{size}
    """)
    List<DetectionJob> selectByUserWithCursor(
        @Param("userId") Long userId,
        @Param("lastId") Long lastId,
        @Param("size") Integer size
    );
}

// æ‰¹é‡æ’å…¥ä¼˜åŒ–
@Service
public class ImageService {
    
    public void batchInsert(List<Image> images) {
        // ä½¿ç”¨MyBatis Plusæ‰¹é‡æ’å…¥
        this.saveBatch(images, 1000); // æ¯æ‰¹1000æ¡
    }
}
```

#### 9.1.3 è¿æ¥æ± ä¼˜åŒ–

```yaml
spring:
  datasource:
    druid:
      initial-size: 10
      min-idle: 10
      max-active: 50
      max-wait: 60000
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 1
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
```

### 9.2 ç¼“å­˜ä¼˜åŒ–

#### 9.2.1 å¤šçº§ç¼“å­˜æ¶æ„

```java
@Configuration
@EnableCaching
public class CacheConfig {
    
    /**
     * æœ¬åœ°ç¼“å­˜ï¼ˆCaffeineï¼‰
     */
    @Bean
    public CacheManager localCacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(1000)
            .expireAfterWrite(10, TimeUnit.MINUTES)
            .recordStats());
        return cacheManager;
    }
    
    /**
     * åˆ†å¸ƒå¼ç¼“å­˜ï¼ˆRedisï¼‰
     */
    @Bean
    public CacheManager redisCacheManager(RedisConnectionFactory factory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofMinutes(30))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new GenericJackson2JsonRedisSerializer()))
            .disableCachingNullValues();
        
        return RedisCacheManager.builder(factory)
            .cacheDefaults(config)
            .build();
    }
}

/**
 * ä½¿ç”¨ç¼“å­˜
 */
@Service
public class DetectionResultService {
    
    // L1ç¼“å­˜ï¼šæœ¬åœ°ç¼“å­˜
    @Cacheable(value = "result", key = "#resultId", 
               cacheManager = "localCacheManager")
    public DetectionResult getResultFromL1(Long resultId) {
        return getResultFromL2(resultId);
    }
    
    // L2ç¼“å­˜ï¼šRedisç¼“å­˜
    @Cacheable(value = "result", key = "#resultId",
               cacheManager = "redisCacheManager")
    public DetectionResult getResultFromL2(Long resultId) {
        return resultMapper.selectById(resultId);
    }
    
    // ç¼“å­˜æ›´æ–°
    @CacheEvict(value = "result", key = "#result.id", allEntries = false)
    public void updateResult(DetectionResult result) {
        resultMapper.updateById(result);
    }
}
```

#### 9.2.2 ç¼“å­˜é¢„çƒ­

```java
@Component
public class CacheWarmUpService {
    
    @Autowired
    private ModelMapper modelMapper;
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    /**
     * åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­ç¼“å­˜
     */
    @PostConstruct
    public void warmUp() {
        log.info("å¼€å§‹ç¼“å­˜é¢„çƒ­...");
        
        // é¢„çƒ­æ´»è·ƒæ¨¡å‹ä¿¡æ¯
        List<Model> activeModels = modelMapper.selectList(
            new LambdaQueryWrapper<Model>().eq(Model::getIsActive, true)
        );
        
        for (Model model : activeModels) {
            String key = "model:" + model.getId();
            redisTemplate.opsForValue().set(key, model, 1, TimeUnit.HOURS);
        }
        
        log.info("ç¼“å­˜é¢„çƒ­å®Œæˆï¼Œé¢„çƒ­{}ä¸ªæ¨¡å‹", activeModels.size());
    }
}
```

### 9.3 å¼‚æ­¥å¤„ç†ä¼˜åŒ–

#### 9.3.1 çº¿ç¨‹æ± é…ç½®

```java
@Configuration
@EnableAsync
public class AsyncConfig implements AsyncConfigurer {
    
    @Bean(name = "taskExecutor")
    public Executor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(10);
        executor.setMaxPoolSize(50);
        executor.setQueueCapacity(1000);
        executor.setThreadNamePrefix("async-task-");
        executor.setKeepAliveSeconds(60);
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.setAwaitTerminationSeconds(60);
        executor.initialize();
        return executor;
    }
    
    @Override
    public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
        return (throwable, method, params) -> {
            log.error("å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸, method: {}, params: {}", 
                      method.getName(), params, throwable);
        };
    }
}

/**
 * ä½¿ç”¨å¼‚æ­¥å¤„ç†
 */
@Service
public class InferenceAsyncService {
    
    @Async("taskExecutor")
    public CompletableFuture<DetectionResult> processAsync(DetectionJob job) {
        try {
            DetectionResult result = executeInference(job);
            return CompletableFuture.completedFuture(result);
        } catch (Exception e) {
            return CompletableFuture.failedFuture(e);
        }
    }
}
```

### 9.4 æ¨¡å‹æ¨ç†ä¼˜åŒ–

#### 9.4.1 æ‰¹å¤„ç†æ¨ç†

```python
# python-inference/app/batch_inference.py
import torch
from typing import List
import numpy as np

class BatchInferenceService:
    """æ‰¹é‡æ¨ç†æœåŠ¡"""
    
    def __init__(self, model, batch_size=8):
        self.model = model
        self.batch_size = batch_size
        self.image_queue = []
    
    async def add_to_batch(self, image: np.ndarray) -> int:
        """æ·»åŠ åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—"""
        self.image_queue.append(image)
        batch_id = len(self.image_queue) - 1
        
        # å½“é˜Ÿåˆ—æ»¡æˆ–è¶…æ—¶æ—¶è§¦å‘æ‰¹å¤„ç†
        if len(self.image_queue) >= self.batch_size:
            await self.process_batch()
        
        return batch_id
    
    async def process_batch(self):
        """å¤„ç†æ‰¹æ¬¡"""
        if not self.image_queue:
            return
        
        # å †å å›¾åƒä¸ºæ‰¹é‡å¼ é‡
        batch_images = torch.stack([
            torch.from_numpy(img) for img in self.image_queue
        ])
        
        # æ‰¹é‡æ¨ç†
        with torch.no_grad():
            batch_results = self.model(batch_images)
        
        # æ¸…ç©ºé˜Ÿåˆ—
        self.image_queue.clear()
        
        return batch_results
```

#### 9.4.2 æ¨¡å‹é‡åŒ–

```python
# æ¨¡å‹é‡åŒ–ï¼ˆINT8ï¼‰
import torch.quantization as quantization

def quantize_model(model, calibration_data):
    """é‡åŒ–æ¨¡å‹ä»¥æå‡æ¨ç†é€Ÿåº¦"""
    
    # é…ç½®é‡åŒ–
    model.qconfig = quantization.get_default_qconfig('fbgemm')
    
    # å‡†å¤‡é‡åŒ–
    model_prepared = quantization.prepare(model)
    
    # æ ¡å‡†ï¼ˆä½¿ç”¨ä¸€å°éƒ¨åˆ†æ•°æ®ï¼‰
    for data in calibration_data:
        model_prepared(data)
    
    # è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
    model_quantized = quantization.convert(model_prepared)
    
    return model_quantized
```

#### 9.4.3 TensorRTä¼˜åŒ–

```python
# ä½¿ç”¨TensorRTåŠ é€Ÿ
import torch_tensorrt

def convert_to_tensorrt(model, input_shape):
    """è½¬æ¢ä¸ºTensorRTæ ¼å¼"""
    
    model_trt = torch_tensorrt.compile(
        model,
        inputs=[torch_tensorrt.Input(input_shape)],
        enabled_precisions={torch.float16},  # ä½¿ç”¨FP16
        workspace_size=1 << 30  # 1GB
    )
    
    return model_trt
```

### 9.5 ç½‘ç»œä¼˜åŒ–

#### 9.5.1 HTTP/2æ”¯æŒ

```yaml
# application.yml
server:
  http2:
    enabled: true
  compression:
    enabled: true
    mime-types: application/json,application/xml,text/html,text/xml,text/plain
    min-response-size: 1024
```

#### 9.5.2 gRPCé€šä¿¡ï¼ˆJavaä¸Pythonï¼‰

```java
// gRPCæœåŠ¡å®šä¹‰ï¼ˆprotoæ–‡ä»¶ï¼‰
syntax = "proto3";

package inference;

service InferenceService {
  rpc Detect(DetectRequest) returns (DetectResponse);
  rpc BatchDetect(BatchDetectRequest) returns (stream DetectResponse);
}

message DetectRequest {
  bytes image_data = 1;
  float threshold = 2;
  int32 min_area = 3;
}

message DetectResponse {
  string job_id = 1;
  repeated Crack cracks = 2;
  float confidence = 3;
}
```

---

## 10. å®‰å…¨æ–¹æ¡ˆ

### 10.1 è®¤è¯ä¸æˆæƒ

#### 10.1.1 JWTé…ç½®

```java
@Configuration
public class SecurityConfig {
    
    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http
            .csrf().disable()
            .sessionManagement()
                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)
            .and()
            .authorizeHttpRequests(auth -> auth
                // å…¬å¼€æ¥å£
                .requestMatchers("/api/v1/auth/**").permitAll()
                .requestMatchers("/actuator/health").permitAll()
                .requestMatchers("/swagger-ui/**", "/v3/api-docs/**").permitAll()
                // éœ€è¦è®¤è¯çš„æ¥å£
                .requestMatchers("/api/v1/datasets/**")
                    .hasAnyRole("USER", "ADMIN")
                .requestMatchers("/api/v1/inference/**")
                    .hasAnyRole("USER", "ADMIN")
                .requestMatchers("/api/v1/admin/**")
                    .hasRole("ADMIN")
                // å…¶ä»–è¯·æ±‚éƒ½éœ€è¦è®¤è¯
                .anyRequest().authenticated()
            )
            .addFilterBefore(jwtAuthenticationFilter(), 
                UsernamePasswordAuthenticationFilter.class);
        
        return http.build();
    }
}
```

#### 10.1.2 APIé™æµ

```java
@Component
public class RateLimitFilter extends OncePerRequestFilter {
    
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @Override
    protected void doFilterInternal(HttpServletRequest request, 
                                   HttpServletResponse response,
                                   FilterChain filterChain) 
            throws ServletException, IOException {
        
        String userId = getUserIdFromRequest(request);
        String key = "rate_limit:" + userId;
        
        // ä»¤ç‰Œæ¡¶ç®—æ³•
        Long count = redisTemplate.opsForValue().increment(key);
        if (count == 1) {
            redisTemplate.expire(key, 1, TimeUnit.MINUTES);
        }
        
        if (count > 100) { // æ¯åˆ†é’Ÿ100æ¬¡
            response.setStatus(429);
            response.getWriter().write("è¯·æ±‚è¿‡äºé¢‘ç¹");
            return;
        }
        
        filterChain.doFilter(request, response);
    }
}
```

### 10.2 æ•°æ®å®‰å…¨

#### 10.2.1 æ•æ„Ÿæ•°æ®åŠ å¯†

```java
@Component
public class EncryptionService {
    
    @Value("${encryption.secret-key}")
    private String secretKey;
    
    /**
     * AESåŠ å¯†
     */
    public String encrypt(String plainText) throws Exception {
        SecretKeySpec keySpec = new SecretKeySpec(
            secretKey.getBytes(), "AES");
        Cipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding");
        cipher.init(Cipher.ENCRYPT_MODE, keySpec);
        byte[] encrypted = cipher.doFinal(plainText.getBytes());
        return Base64.getEncoder().encodeToString(encrypted);
    }
    
    /**
     * AESè§£å¯†
     */
    public String decrypt(String encryptedText) throws Exception {
        SecretKeySpec keySpec = new SecretKeySpec(
            secretKey.getBytes(), "AES");
        Cipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding");
        cipher.init(Cipher.DECRYPT_MODE, keySpec);
        byte[] decrypted = cipher.doFinal(
            Base64.getDecoder().decode(encryptedText));
        return new String(decrypted);
    }
}

// åœ¨å®ä½“ç±»ä¸­ä½¿ç”¨
@Data
public class User {
    private Long id;
    private String username;
    
    @TableField(typeHandler = EncryptedStringTypeHandler.class)
    private String phone; // åŠ å¯†å­˜å‚¨
    
    @TableField(typeHandler = EncryptedStringTypeHandler.class)
    private String email; // åŠ å¯†å­˜å‚¨
}
```

#### 10.2.2 SQLæ³¨å…¥é˜²æŠ¤

```java
// ä½¿ç”¨MyBatis Plusé˜²æ­¢SQLæ³¨å…¥
@Mapper
public interface UserMapper extends BaseMapper<User> {
    
    // æ­£ç¡®ï¼šä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
    @Select("SELECT * FROM sys_user WHERE username = #{username}")
    User findByUsername(@Param("username") String username);
    
    // é”™è¯¯ï¼šå­—ç¬¦ä¸²æ‹¼æ¥ï¼ˆå®¹æ˜“SQLæ³¨å…¥ï¼‰
    // @Select("SELECT * FROM sys_user WHERE username = '" + username + "'")
}
```

### 10.3 æ¥å£å®‰å…¨

#### 10.3.1 å‚æ•°æ ¡éªŒ

```java
/**
 * ä½¿ç”¨JSR-303éªŒè¯
 */
@Data
public class LoginRequest {
    
    @NotBlank(message = "ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
    @Size(min = 3, max = 50, message = "ç”¨æˆ·åé•¿åº¦å¿…é¡»åœ¨3-50ä¹‹é—´")
    @Pattern(regexp = "^[a-zA-Z0-9_]+$", message = "ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯æ•°å­—ä¸‹åˆ’çº¿")
    private String username;
    
    @NotBlank(message = "å¯†ç ä¸èƒ½ä¸ºç©º")
    @Size(min = 6, max = 20, message = "å¯†ç é•¿åº¦å¿…é¡»åœ¨6-20ä¹‹é—´")
    private String password;
    
    @Email(message = "é‚®ç®±æ ¼å¼ä¸æ­£ç¡®")
    private String email;
}

@RestController
public class AuthController {
    
    @PostMapping("/api/v1/auth/login")
    public Result<LoginResponse> login(@Valid @RequestBody LoginRequest request) {
        // @Valid ä¼šè‡ªåŠ¨è§¦å‘éªŒè¯
        return authService.login(request);
    }
}
```

#### 10.3.2 XSSé˜²æŠ¤

```java
/**
 * XSSè¿‡æ»¤å™¨
 */
@Component
public class XssFilter extends OncePerRequestFilter {
    
    @Override
    protected void doFilterInternal(HttpServletRequest request,
                                   HttpServletResponse response,
                                   FilterChain filterChain) 
            throws ServletException, IOException {
        
        XssHttpServletRequestWrapper wrapper = 
            new XssHttpServletRequestWrapper(request);
        filterChain.doFilter(wrapper, response);
    }
}

class XssHttpServletRequestWrapper extends HttpServletRequestWrapper {
    
    public XssHttpServletRequestWrapper(HttpServletRequest request) {
        super(request);
    }
    
    @Override
    public String getParameter(String name) {
        String value = super.getParameter(name);
        return cleanXSS(value);
    }
    
    private String cleanXSS(String value) {
        if (value == null) {
            return null;
        }
        // ç§»é™¤æ½œåœ¨çš„XSSæ”»å‡»å­—ç¬¦
        value = value.replaceAll("<", "&lt;")
                    .replaceAll(">", "&gt;")
                    .replaceAll("\"", "&quot;")
                    .replaceAll("'", "&#x27;")
                    .replaceAll("/", "&#x2F;");
        return value;
    }
}
```

---

## 11. ç›‘æ§ä¸è¿ç»´

### 11.1 æŒ‡æ ‡ç›‘æ§

#### 11.1.1 Spring Boot Actuatoré…ç½®

```yaml
# application.yml
management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-details: always
    metrics:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
```

#### 11.1.2 è‡ªå®šä¹‰æŒ‡æ ‡

```java
@Component
public class InferenceMetrics {
    
    private final Counter inferenceCounter;
    private final Timer inferenceTimer;
    private final Gauge activeJobs;
    
    public InferenceMetrics(MeterRegistry registry) {
        this.inferenceCounter = Counter.builder("inference.requests.total")
            .description("æ¨ç†è¯·æ±‚æ€»æ•°")
            .tags("service", "inference")
            .register(registry);
        
        this.inferenceTimer = Timer.builder("inference.duration")
            .description("æ¨ç†è€—æ—¶")
            .tags("service", "inference")
            .register(registry);
        
        this.activeJobs = Gauge.builder("inference.jobs.active",
                this, InferenceMetrics::getActiveJobCount)
            .description("æ´»è·ƒä»»åŠ¡æ•°")
            .register(registry);
    }
    
    public void recordInference(Runnable task) {
        inferenceCounter.increment();
        inferenceTimer.record(task);
    }
    
    private long getActiveJobCount() {
        // æŸ¥è¯¢æ´»è·ƒä»»åŠ¡æ•°
        return jobMapper.selectCount(
            new LambdaQueryWrapper<DetectionJob>()
                .eq(DetectionJob::getStatus, "running")
        );
    }
}
```

### 11.2 æ—¥å¿—ç®¡ç†

#### 11.2.1 æ—¥å¿—é…ç½®

```xml
<!-- logback-spring.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- æ§åˆ¶å°è¾“å‡º -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- æ–‡ä»¶è¾“å‡º -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/crack-detection.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/crack-detection.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy 
                class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- Logstashè¾“å‡º -->
    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>logstash:5000</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <includeMdcKeyName>traceId</includeMdcKeyName>
            <includeMdcKeyName>userId</includeMdcKeyName>
        </encoder>
    </appender>
    
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="FILE"/>
        <appender-ref ref="LOGSTASH"/>
    </root>
</configuration>
```

#### 11.2.2 é“¾è·¯è¿½è¸ª

```java
/**
 * ä½¿ç”¨Sleuthå®ç°åˆ†å¸ƒå¼è¿½è¸ª
 */
@Component
public class TraceInterceptor implements HandlerInterceptor {
    
    @Override
    public boolean preHandle(HttpServletRequest request,
                            HttpServletResponse response,
                            Object handler) {
        String traceId = UUID.randomUUID().toString();
        MDC.put("traceId", traceId);
        response.setHeader("X-Trace-Id", traceId);
        return true;
    }
    
    @Override
    public void afterCompletion(HttpServletRequest request,
                               HttpServletResponse response,
                               Object handler,
                               Exception ex) {
        MDC.clear();
    }
}
```

### 11.3 å‘Šè­¦é…ç½®

#### 11.3.1 Prometheuså‘Šè­¦è§„åˆ™

```yaml
# monitoring/prometheus/alert_rules.yml
groups:
  - name: crack_detection_alerts
    interval: 30s
    rules:
      # CPUä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighCPUUsage
        expr: process_cpu_usage > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "{{ $labels.instance }} CPUä½¿ç”¨ç‡è¶…è¿‡80%"
      
      # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighMemoryUsage
        expr: jvm_memory_used_bytes / jvm_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "{{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%"
      
      # APIå“åº”æ—¶é—´è¿‡é•¿
      - alert: SlowAPIResponse
        expr: http_server_requests_seconds_sum / http_server_requests_seconds_count > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "APIå“åº”æ—¶é—´è¿‡é•¿"
          description: "å¹³å‡å“åº”æ—¶é—´è¶…è¿‡5ç§’"
      
      # æ¨ç†å¤±è´¥ç‡è¿‡é«˜
      - alert: HighInferenceFailureRate
        expr: rate(inference_requests_total{status="failed"}[5m]) / rate(inference_requests_total[5m]) > 0.1
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "æ¨ç†å¤±è´¥ç‡è¿‡é«˜"
          description: "æ¨ç†å¤±è´¥ç‡è¶…è¿‡10%"
      
      # æœåŠ¡ä¸å¯ç”¨
      - alert: ServiceDown
        expr: up{job="inference-service"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æœåŠ¡ä¸å¯ç”¨"
          description: "{{ $labels.instance }} æœåŠ¡å·²å®•æœº"
```

---

## 12. å¼€å‘è®¡åˆ’

### 12.1 é¡¹ç›®å‘¨æœŸï¼ˆ21å‘¨ï¼‰

#### Phase 1: éœ€æ±‚åˆ†æä¸æ¶æ„è®¾è®¡ï¼ˆ2å‘¨ï¼‰

**Week 1: éœ€æ±‚è°ƒç ”**
- [ ] æ·±å…¥å­¦ä¹ ä»»åŠ¡ä¹¦è¦æ±‚
- [ ] ç ”ç©¶å‚è€ƒæ–‡çŒ®ï¼Œç†è§£è£‚çº¹æ£€æµ‹éœ€æ±‚
- [ ] è°ƒç ”å…¬å¼€æ•°æ®é›†ï¼ˆRDD2022ã€Crack500ç­‰ï¼‰
- [ ] ç»˜åˆ¶UMLç”¨ä¾‹å›¾å’Œæµç¨‹å›¾

**Week 2: æŠ€æœ¯é€‰å‹ä¸æ¶æ„è®¾è®¡**
- [ ] ç¡®å®šæŠ€æœ¯æ ˆï¼ˆJava + Pythonæ··åˆæ¶æ„ï¼‰
- [ ] è®¾è®¡ç³»ç»Ÿæ¶æ„å›¾
- [ ] è®¾è®¡æ•°æ®åº“è¡¨ç»“æ„
- [ ] è®¾è®¡APIæ¥å£è§„èŒƒ
- [ ] ç¼–å†™è¯¦ç»†è®¾è®¡æ–‡æ¡£

#### Phase 2: åŸºç¡€è®¾æ–½æ­å»ºï¼ˆ2å‘¨ï¼‰

**Week 3: å¼€å‘ç¯å¢ƒæ­å»º**
- [ ] å®‰è£…Java 17ã€Mavenã€Docker
- [ ] æ­å»ºPostgreSQLã€Redisã€MinIOã€RabbitMQ
- [ ] åˆ›å»ºMavenå¤šæ¨¡å—é¡¹ç›®
- [ ] é…ç½®NacosæœåŠ¡æ³¨å†Œä¸­å¿ƒ
- [ ] æ­å»ºGitä»“åº“ï¼Œé…ç½®.gitignore

**Week 4: CI/CDæµç¨‹**
- [ ] ç¼–å†™Dockerfile
- [ ] é…ç½®docker-compose.yml
- [ ] æ­å»ºGitLab CI/CDæµç¨‹
- [ ] é…ç½®ä»£ç è´¨é‡æ£€æŸ¥ï¼ˆSonarQubeï¼‰
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•æ¡†æ¶

#### Phase 3: æ•°æ®å¤„ç†æ¨¡å—ï¼ˆ3å‘¨ï¼‰

**Week 5: æ•°æ®åŠ è½½ä¸æ ¼å¼è½¬æ¢**
- [ ] å®ç°COCOæ ¼å¼è§£æå™¨
- [ ] å®ç°VOCæ ¼å¼è§£æå™¨
- [ ] å®ç°YOLOæ ¼å¼è§£æå™¨
- [ ] å®ç°æ•°æ®æ ¼å¼ç»Ÿä¸€è½¬æ¢
- [ ] å•å…ƒæµ‹è¯•

**Week 6: æ•°æ®é¢„å¤„ç†æµæ°´çº¿**
- [ ] å®ç°æ•°æ®é›†åˆ’åˆ†ï¼ˆtrain/val/testï¼‰
- [ ] å®ç°æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€äº®åº¦è°ƒæ•´ç­‰ï¼‰
- [ ] å®ç°å›¾åƒåˆ‡ç‰‡ä¸æ ‡å‡†åŒ–
- [ ] é›†æˆMinIOå¯¹è±¡å­˜å‚¨
- [ ] ç¼–å†™é¢„å¤„ç†APIæ¥å£

**Week 7: æµ‹è¯•ä¸ä¼˜åŒ–**
- [ ] é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•ï¼ˆå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼‰
- [ ] ä¼˜åŒ–é¢„å¤„ç†é€Ÿåº¦
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£

#### Phase 4: æ¨¡å‹è®­ç»ƒä¸ä¼˜åŒ–ï¼ˆ4å‘¨ï¼‰

**Week 8: U-NetåŸºç¡€æ¨¡å‹**
- [ ] å®ç°U-NetåŸºç¡€æ¶æ„ï¼ˆPython + PyTorchï¼‰
- [ ] å®ç°æ•°æ®åŠ è½½å™¨ï¼ˆDataLoaderï¼‰
- [ ] å®ç°è®­ç»ƒå¾ªç¯
- [ ] éªŒè¯æ¨¡å‹å¯ä»¥æ­£å¸¸è®­ç»ƒ

**Week 9: æ¨¡å‹æ”¹è¿›**
- [ ] æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶ï¼ˆCBAMï¼‰
- [ ] æ·»åŠ ASPPæ¨¡å—
- [ ] å®ç°æ·±åº¦ç›‘ç£
- [ ] å®ç°ç»„åˆæŸå¤±å‡½æ•°ï¼ˆDice + Focal + BCEï¼‰

**Week 10: æ¨¡å‹è®­ç»ƒä¸è°ƒå‚**
- [ ] åœ¨RDD2022æ•°æ®é›†ä¸Šè®­ç»ƒ
- [ ] è¶…å‚æ•°è°ƒä¼˜ï¼ˆå­¦ä¹ ç‡ã€batch sizeç­‰ï¼‰
- [ ] æ•°æ®å¢å¼ºç­–ç•¥ä¼˜åŒ–
- [ ] ä½¿ç”¨MLflowè·Ÿè¸ªå®éªŒ

**Week 11: æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–**
- [ ] åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆIoUã€Recallã€Precisionï¼‰
- [ ] åˆ†æé”™è¯¯æ¡ˆä¾‹
- [ ] ä¼˜åŒ–æ¨¡å‹ç»“æ„
- [ ] ç¡®ä¿IoU â‰¥ 85%

#### Phase 5: Pythonæ¨ç†æœåŠ¡ï¼ˆ2å‘¨ï¼‰

**Week 12: FastAPIæœåŠ¡æ­å»º**
- [ ] æ­å»ºFastAPIé¡¹ç›®ç»“æ„
- [ ] å®ç°æ¨¡å‹åŠ è½½å™¨
- [ ] å®ç°å›¾åƒé¢„å¤„ç†
- [ ] å®ç°æ¨¡å‹æ¨ç†æ¥å£
- [ ] å®ç°åå¤„ç†ï¼ˆè½®å»“æå–ã€å±æ€§è®¡ç®—ï¼‰

**Week 13: ä¼˜åŒ–ä¸æµ‹è¯•**
- [ ] å®ç°æ‰¹é‡æ¨ç†
- [ ] æ¨¡å‹é‡åŒ–ä¼˜åŒ–
- [ ] TensorRTåŠ é€Ÿï¼ˆå¯é€‰ï¼‰
- [ ] æ€§èƒ½æµ‹è¯•ï¼ˆç¡®ä¿â‰¤5ç§’/å¼ ï¼‰
- [ ] Dockerå®¹å™¨åŒ–

#### Phase 6: Javaä¸šåŠ¡æœåŠ¡ï¼ˆ3å‘¨ï¼‰

**Week 14: è®¤è¯ä¸æ•°æ®é›†æœåŠ¡**
- [ ] å®ç°ç”¨æˆ·è®¤è¯æœåŠ¡ï¼ˆJWTï¼‰
- [ ] å®ç°æƒé™ç®¡ç†ï¼ˆRBACï¼‰
- [ ] å®ç°æ•°æ®é›†ç®¡ç†æœåŠ¡
- [ ] å®ç°æ•°æ®é›†å¯¼å…¥API
- [ ] é›†æˆæµ‹è¯•

**Week 15: æ¨ç†æœåŠ¡**
- [ ] å®ç°æ¨ç†ä»»åŠ¡ç®¡ç†
- [ ] ä½¿ç”¨Feignè°ƒç”¨PythonæœåŠ¡
- [ ] å®ç°ç»“æœå¤„ç†ä¸å­˜å‚¨
- [ ] å®ç°æ‰¹é‡æ¨ç†
- [ ] å®ç°WebSocketå®æ—¶æ¨é€

**Week 16: å¯è§†åŒ–ä¸æŠ¥å‘ŠæœåŠ¡**
- [ ] å®ç°å›¾åƒå åŠ ç”Ÿæˆ
- [ ] å®ç°çƒ­åŠ›å›¾ç”Ÿæˆ
- [ ] å®ç°ç»Ÿè®¡åˆ†æ
- [ ] å®ç°PDFæŠ¥å‘Šç”Ÿæˆ
- [ ] å®ç°Excelæ•°æ®å¯¼å‡º

#### Phase 7: å‰ç«¯å¼€å‘ï¼ˆ3å‘¨ï¼‰

**Week 17: åŸºç¡€æ¡†æ¶æ­å»º**
- [ ] åˆ›å»ºVue 3é¡¹ç›®
- [ ] é…ç½®è·¯ç”±å’ŒçŠ¶æ€ç®¡ç†
- [ ] å®ç°ç™»å½•æ³¨å†Œé¡µé¢
- [ ] å®ç°ä¸»æ¡†æ¶å¸ƒå±€
- [ ] é›†æˆElement Plus

**Week 18: æ ¸å¿ƒåŠŸèƒ½é¡µé¢**
- [ ] å®ç°æ•°æ®é›†ç®¡ç†é¡µé¢
- [ ] å®ç°è£‚çº¹æ£€æµ‹é¡µé¢
- [ ] å®ç°å›¾åƒæŸ¥çœ‹å™¨
- [ ] å®ç°ç»“æœå¯è§†åŒ–
- [ ] å®ç°ç»Ÿè®¡å›¾è¡¨

**Week 19: é«˜çº§åŠŸèƒ½**
- [ ] å®ç°æ ‡æ³¨å·¥å…·
- [ ] å®ç°æŠ¥å‘Šç”ŸæˆåŠŸèƒ½
- [ ] å®ç°ç”¨æˆ·ç®¡ç†ï¼ˆç®¡ç†å‘˜ï¼‰
- [ ] ä¼˜åŒ–äº¤äº’ä½“éªŒ
- [ ] å“åº”å¼å¸ƒå±€é€‚é…

#### Phase 8: ç³»ç»Ÿé›†æˆä¸æµ‹è¯•ï¼ˆ2å‘¨ï¼‰

**Week 20: é›†æˆä¸è”è°ƒ**
- [ ] å‰åç«¯é›†æˆ
- [ ] ç«¯åˆ°ç«¯åŠŸèƒ½æµ‹è¯•
- [ ] ä¿®å¤é›†æˆé—®é¢˜
- [ ] æ€§èƒ½æµ‹è¯•ä¸ä¼˜åŒ–
- [ ] å®‰å…¨æµ‹è¯•

**Week 21: å‹åŠ›æµ‹è¯•ä¸ä¼˜åŒ–**
- [ ] å¹¶å‘æµ‹è¯•ï¼ˆ100+ç”¨æˆ·ï¼‰
- [ ] æ‰¹é‡å¤„ç†æµ‹è¯•ï¼ˆâ‰¥10å¼ /ç§’ï¼‰
- [ ] ç³»ç»Ÿå¯ç”¨æ€§æµ‹è¯•ï¼ˆâ‰¥99.5%ï¼‰
- [ ] ä¼˜åŒ–ç“¶é¢ˆ
- [ ] æœ€ç»ˆéªŒæ”¶

#### Phase 9: æ–‡æ¡£ä¸éƒ¨ç½²ï¼ˆ1å‘¨ï¼‰

**Week 22: æ–‡æ¡£ä¸äº¤ä»˜**
- [ ] ç¼–å†™ç³»ç»Ÿæ¶æ„æ–‡æ¡£
- [ ] ç¼–å†™APIæ¥å£æ–‡æ¡£
- [ ] ç¼–å†™éƒ¨ç½²è¿ç»´æ–‡æ¡£
- [ ] ç¼–å†™ç”¨æˆ·ä½¿ç”¨æ‰‹å†Œ
- [ ] å½•åˆ¶æ¼”ç¤ºè§†é¢‘
- [ ] å‡†å¤‡ç­”è¾©ææ–™

### 12.2 é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | å‘¨æ¬¡ | äº¤ä»˜ç‰© | æˆåŠŸæ ‡å‡† |
|-------|------|--------|----------|
| **M1: æ¶æ„è®¾è®¡å®Œæˆ** | Week 2 | ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ | é€šè¿‡è®¾è®¡è¯„å®¡ |
| **M2: åŸºç¡€è®¾æ–½å°±ç»ª** | Week 4 | å¼€å‘ç¯å¢ƒã€CI/CD | æ‰€æœ‰æœåŠ¡å¯å¯åŠ¨ |
| **M3: æ•°æ®å¤„ç†å®Œæˆ** | Week 7 | æ•°æ®å¤„ç†æ¨¡å— | å¯å¤„ç†RDD2022æ•°æ®é›† |
| **M4: æ¨¡å‹è¾¾æ ‡** | Week 11 | è®­ç»ƒå¥½çš„æ¨¡å‹ | IoU â‰¥ 85% |
| **M5: æ¨ç†æœåŠ¡å®Œæˆ** | Week 13 | Pythonæ¨ç†æœåŠ¡ | â‰¤5ç§’/å¼  |
| **M6: åç«¯æœåŠ¡å®Œæˆ** | Week 16 | Javaå¾®æœåŠ¡ | æ‰€æœ‰APIå¯ç”¨ |
| **M7: å‰ç«¯å®Œæˆ** | Week 19 | Webåº”ç”¨ | æ ¸å¿ƒåŠŸèƒ½å¯ç”¨ |
| **M8: ç³»ç»Ÿé›†æˆå®Œæˆ** | Week 21 | å®Œæ•´ç³»ç»Ÿ | é€šè¿‡æ‰€æœ‰æµ‹è¯• |
| **M9: æœ€ç»ˆäº¤ä»˜** | Week 22 | å®Œæ•´äº¤ä»˜ç‰© | å¯æ¼”ç¤ºå’Œç­”è¾© |

### 12.3 é£é™©ç®¡ç†

| é£é™© | å½±å“ | æ¦‚ç‡ | åº”å¯¹æªæ–½ |
|------|------|------|----------|
| æ¨¡å‹ç²¾åº¦ä¸è¾¾æ ‡ | é«˜ | ä¸­ | å¤šæ¬¡è¿­ä»£ä¼˜åŒ–ï¼Œå°è¯•å¤šç§æ¨¡å‹æ¶æ„ |
| æ¨ç†é€Ÿåº¦æ…¢ | é«˜ | ä¸­ | æ¨¡å‹é‡åŒ–ã€TensorRTåŠ é€Ÿã€æ‰¹å¤„ç† |
| æ•°æ®é›†è´¨é‡é—®é¢˜ | ä¸­ | ä½ | ä½¿ç”¨å¤šä¸ªæ•°æ®é›†ï¼Œæ•°æ®æ¸…æ´— |
| å¼€å‘è¿›åº¦å»¶è¿Ÿ | é«˜ | ä¸­ | ä¼˜å…ˆæ ¸å¿ƒåŠŸèƒ½ï¼Œç æ‰éå¿…è¦åŠŸèƒ½ |
| GPUèµ„æºä¸è¶³ | ä¸­ | ä¸­ | ä½¿ç”¨äº‘GPUï¼ˆé˜¿é‡Œäº‘/è…¾è®¯äº‘ï¼‰ |
| ç³»ç»Ÿç¨³å®šæ€§é—®é¢˜ | ä¸­ | ä½ | å……åˆ†æµ‹è¯•ï¼Œæ·»åŠ ç†”æ–­é™çº§ |

---

## 13. æ€»ç»“

æœ¬ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆé‡‡ç”¨**Java + Pythonæ··åˆå¾®æœåŠ¡æ¶æ„**ï¼Œå……åˆ†å‘æŒ¥äº†ä¸¤ç§è¯­è¨€çš„ä¼˜åŠ¿ï¼š

âœ… **Javaåç«¯ä¼˜åŠ¿**ï¼š
- é«˜æ€§èƒ½ã€é«˜å¹¶å‘å¤„ç†èƒ½åŠ›
- ç±»å‹å®‰å…¨ï¼Œä»£ç å¯ç»´æŠ¤æ€§å¼º
- Springç”Ÿæ€å®Œå–„ï¼Œå¼€å‘æ•ˆç‡é«˜
- é€‚åˆå¤„ç†ä¸šåŠ¡é€»è¾‘ã€æ•°æ®ç®¡ç†

âœ… **Python AIä¼˜åŠ¿**ï¼š
- AI/MLç”Ÿæ€æœ€å¼ºï¼ˆPyTorchã€OpenCVï¼‰
- å›¾åƒå¤„ç†æ–¹ä¾¿
- æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çµæ´»
- é€‚åˆå¤„ç†æ·±åº¦å­¦ä¹ ä»»åŠ¡

âœ… **ç³»ç»Ÿç‰¹ç‚¹**ï¼š
- **å¾®æœåŠ¡æ¶æ„**ï¼šæ¨¡å—è§£è€¦ï¼Œç‹¬ç«‹éƒ¨ç½²ï¼Œæ˜“äºæ‰©å±•
- **äº‘ç«¯ååŒ**ï¼šåˆ†å¸ƒå¼éƒ¨ç½²ï¼Œå¼¹æ€§ä¼¸ç¼©ï¼Œé«˜å¯ç”¨
- **é«˜æ€§èƒ½**ï¼šå¤šçº§ç¼“å­˜ï¼Œå¼‚æ­¥å¤„ç†ï¼Œæ‰¹é‡æ¨ç†
- **é«˜å®‰å…¨æ€§**ï¼šJWTè®¤è¯ï¼Œæ•°æ®åŠ å¯†ï¼Œæƒé™æ§åˆ¶
- **å¯è§‚æµ‹æ€§**ï¼šå®Œå–„çš„ç›‘æ§ã€æ—¥å¿—ã€è¿½è¸ªä½“ç³»

âœ… **æŠ€æœ¯æŒ‡æ ‡**ï¼š
- æ£€æµ‹ç²¾åº¦ï¼šIoU â‰¥ 85%ï¼Œå¬å›ç‡ â‰¥ 80%
- å¤„ç†æ€§èƒ½ï¼šâ‰¤ 5ç§’/å¼ ï¼Œâ‰¥ 10å¼ /ç§’æ‰¹é‡
- ç³»ç»Ÿå¯ç”¨æ€§ï¼šâ‰¥ 99.5%
- å¹¶å‘èƒ½åŠ›ï¼šâ‰¥ 100ç”¨æˆ·

æœ¬æ–¹æ¡ˆç»è¿‡å……åˆ†çš„æŠ€æœ¯è°ƒç ”å’Œè¯¦ç»†è®¾è®¡ï¼Œå…·æœ‰è‰¯å¥½çš„å¯è¡Œæ€§å’Œæ‰©å±•æ€§ï¼Œå¯ä»¥æ»¡è¶³æ¯•ä¸šè®¾è®¡çš„æ‰€æœ‰è¦æ±‚ã€‚

---

**æ–‡æ¡£ç¼–å†™**: é«˜ç»…è¯­  
**æŒ‡å¯¼æ•™å¸ˆ**: æ¨é£  
**å­¦æ ¡**: å±±ä¸œå¤§å­¦  
**å­¦é™¢**: ä½ç©ºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢  
**ä¸“ä¸š**: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ï¼ˆæœªæ¥ç½‘ç»œï¼‰  
**æ›´æ–°æ—¶é—´**: 2025-11-06

