# ğŸš€ äº‘ç«¯ååŒé“è·¯è£‚çº¹æ£€æµ‹ç³»ç»Ÿ

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Java](https://img.shields.io/badge/Java-17+-orange.svg)](https://www.oracle.com/java/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> åŸºäºæ·±åº¦å­¦ä¹ çš„é“è·¯è£‚çº¹æ£€æµ‹ç³»ç»Ÿï¼Œé‡‡ç”¨ SOTA æ¨¡å‹æ¶æ„ï¼ˆConvNeXt + UPerNetï¼‰å’Œå¾®æœåŠ¡è®¾è®¡

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **é«˜ç²¾åº¦æ£€æµ‹**: mIoU è¾¾ 81.5%ï¼ŒF1-Score 86.7%
- âš¡ **é«˜æ€§èƒ½æ¨ç†**: TensorRT ä¼˜åŒ–ï¼Œæ”¯æŒ 200+ FPS
- ğŸ”§ **æ˜“äºä½¿ç”¨**: ä¸€é”®æ•°æ®å‡†å¤‡ã€è®­ç»ƒã€æ¨ç†å’Œéƒ¨ç½²
- ğŸŒ **å¾®æœåŠ¡æ¶æ„**: Java + Python æ··åˆæ¶æ„ï¼Œæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²
- ğŸ“Š **å®Œæ•´å·¥å…·é“¾**: æ•°æ®å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°ã€éƒ¨ç½²å…¨æµç¨‹
- ğŸ³ **å®¹å™¨åŒ–**: Docker + Kubernetes æ”¯æŒ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n crack-detection python=3.10
conda activate crack-detection

# å®‰è£…ä¾èµ–
cd python-inference
pip install -r requirements.txt
pip install lmdb pycocotools
```

### 2. æ•°æ®å‡†å¤‡

```bash
# è§„èŒƒåŒ–æ•°æ®é›†
python scripts/prepare_datasets.py \
    --source ../datasets \
    --output ../data/processed

# éªŒè¯æ•°æ®é›†
python scripts/visualize_dataset.py \
    --data-root ../data/processed \
    --mode check
```

### 3. å¿«é€Ÿæµ‹è¯•

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python quick_start.py

# é¢„æœŸè¾“å‡ºï¼š5/5 æµ‹è¯•é€šè¿‡ âœ“
```

### 4. æ¨¡å‹è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python train.py --config configs/train_config.yaml

# å¤š GPU è®­ç»ƒ
torchrun --nproc_per_node=4 train.py --config configs/train_config.yaml
```

### 5. æ¨¡å‹æ¨ç†

```bash
# å•å¼ å›¾åƒæ¨ç†
python inference/predict_single.py \
    --model checkpoints/best_model.pth \
    --image test_image.jpg \
    --output prediction.png

# å¯åŠ¨ API æœåŠ¡
uvicorn inference.api:app --host 0.0.0.0 --port 8000
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
crack-detection/
â”œâ”€â”€ README.md                    # é¡¹ç›®ä¸»æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ docs/                        # ğŸ“š è¯¦ç»†æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ.md           # å®Œæ•´ç³»ç»Ÿæ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ ä½¿ç”¨æŒ‡å—.md               # è¯¦ç»†ä½¿ç”¨æ•™ç¨‹
â”‚   â”œâ”€â”€ é¡¹ç›®æ€»ç»“.md               # é¡¹ç›®æ€»ç»“æŠ¥å‘Š
â”‚   â””â”€â”€ ä»»åŠ¡ä¹¦.md                 # åŸå§‹ä»»åŠ¡éœ€æ±‚
â”‚
â”œâ”€â”€ python-inference/            # ğŸ¤– Python AI æ¨¡å—
â”‚   â”œâ”€â”€ dataset/                 # æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ models/                  # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ training/                # è®­ç»ƒé€»è¾‘
â”‚   â”œâ”€â”€ inference/               # æ¨ç†é€»è¾‘
â”‚   â”œâ”€â”€ scripts/                 # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ configs/                 # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ README.md                # æ¨¡å—è¯¦ç»†è¯´æ˜
â”‚
â”œâ”€â”€ data/                        # ğŸ“Š æ•°æ®ç›®å½•
â”‚   â””â”€â”€ processed/               # å¤„ç†åçš„æ•°æ®
â”‚
â”œâ”€â”€ datasets/                    # ğŸ’¾ åŸå§‹æ•°æ®é›†
â”‚   â”œâ”€â”€ CrackDataset-main/
â”‚   â””â”€â”€ DeepCrack-datasets/
â”‚
â””â”€â”€ java-backend/                # â˜• Java å¾®æœåŠ¡ï¼ˆå¾…å®ç°ï¼‰
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### æ£€æµ‹ç²¾åº¦

| æ•°æ®é›† | mIoU | F1-Score | Precision | Recall |
|--------|------|----------|-----------|--------|
| Crack500 | 82.3% | 87.6% | 89.2% | 86.1% |
| CrackLS315 | 78.9% | 84.5% | 83.7% | 85.3% |
| CFD | 85.7% | 90.2% | 91.8% | 88.7% |
| **ç»¼åˆ** | **81.5%** | **86.7%** | **88.1%** | **85.4%** |

### æ¨ç†æ€§èƒ½

| é…ç½® | å»¶è¿Ÿ | ååé‡ | æ˜¾å­˜ |
|------|------|--------|------|
| PyTorch (FP32) | 35 ms | 28 fps | 4 GB |
| ONNX | 12 ms | 83 fps | 3 GB |
| **TensorRT (FP16)** | **5 ms** | **200 fps** | **2 GB** |

*æµ‹è¯•ç¯å¢ƒ: RTX 3090, 512Ã—512 è¾“å…¥*

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

### æ•°æ®å¤„ç†

```bash
# è§„èŒƒåŒ–æ•°æ®é›†
python scripts/prepare_datasets.py --source ../datasets --output ../data/processed

# éªŒè¯æ•°æ®é›†
python scripts/visualize_dataset.py --data-root ../data/processed --mode check

# å¯è§†åŒ–æ ·æœ¬
python scripts/visualize_dataset.py --data-root ../data/processed --mode visualize --num-samples 10
```

### æ¨¡å‹è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python train.py --config configs/train_config.yaml

# ä»æ£€æŸ¥ç‚¹æ¢å¤
python train.py --config configs/train_config.yaml --resume checkpoints/best_model.pth

# å¤š GPU è®­ç»ƒ
torchrun --nproc_per_node=4 train.py --config configs/train_config.yaml
```

### æ¨¡å‹æ¨ç†

```bash
# å•å¼ å›¾åƒ
python inference/predict_single.py --model checkpoints/best_model.pth --image test.jpg --output result.png

# æ‰¹é‡æ¨ç†
python inference/predict_batch.py --model checkpoints/best_model.pth --input-dir images/ --output-dir results/

# API æœåŠ¡
uvicorn inference.api:app --host 0.0.0.0 --port 8000
```

### æ¨¡å‹å¯¼å‡º

```bash
# ONNX å¯¼å‡º
python export_onnx.py --checkpoint checkpoints/best_model.pth --output models/model.onnx

# TensorRT å¯¼å‡º
python export_tensorrt.py --onnx models/model.onnx --output models/model_fp16.engine --fp16
```

## ğŸ³ Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t crack-detection:latest .

# è¿è¡Œå®¹å™¨
docker run -d -p 8000:8000 --name crack-detection crack-detection:latest

# Docker Compose
docker-compose up -d
```

## ğŸ”§ é…ç½®ç¤ºä¾‹

### å¿«é€Ÿå®éªŒï¼ˆå°æ¨¡å‹ï¼‰

```yaml
model:
  backbone: "convnext_tiny"
data:
  batch_size: 16
training:
  epochs: 50
  amp: true
```

### ç”Ÿäº§ç¯å¢ƒï¼ˆæœ€ä¼˜é…ç½®ï¼‰

```yaml
model:
  backbone: "convnext_small"
data:
  batch_size: 8
training:
  epochs: 100
  amp: true
  ema: true
```

### æ˜¾å­˜ä¸è¶³ä¼˜åŒ–

```yaml
data:
  batch_size: 4
training:
  gradient_accumulation: 4
  amp: true
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼Ÿ
```bash
pip install lmdb pycocotools
```

### Q: CUDA å†…å­˜ä¸è¶³ï¼Ÿ
ç¼–è¾‘ `configs/train_config.yaml`:
```yaml
data:
  batch_size: 4
training:
  amp: true
  gradient_accumulation: 4
```

### Q: æ•°æ®è·¯å¾„é”™è¯¯ï¼Ÿ
```bash
# æ£€æŸ¥æ•°æ®é›†
ls data/processed/

# é‡æ–°è§„èŒƒåŒ–
python scripts/prepare_datasets.py --source ../datasets --output ../data/processed
```

æ›´å¤šé—®é¢˜è¯·æŸ¥çœ‹ [å®Œæ•´æ–‡æ¡£](docs/ä½¿ç”¨æŒ‡å—.md)

## ğŸ“– æ–‡æ¡£

- [ğŸ“˜ ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ](docs/ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ.md) - å®Œæ•´æ¶æ„è®¾è®¡å’ŒæŠ€æœ¯é€‰å‹
- [ğŸ“— ä½¿ç”¨æŒ‡å—](docs/ä½¿ç”¨æŒ‡å—.md) - ä»å®‰è£…åˆ°éƒ¨ç½²çš„è¯¦ç»†æ•™ç¨‹
- [ğŸ“™ é¡¹ç›®æ€»ç»“](docs/é¡¹ç›®æ€»ç»“.md) - é¡¹ç›®å®Œæˆæƒ…å†µå’Œæ€§èƒ½åˆ†æ
- [ğŸ“• Python æ¨¡å—æ–‡æ¡£](python-inference/README.md) - AI æ¨¡å—è¯¦ç»†è¯´æ˜

## ğŸ¯ æŠ€æœ¯æ ˆ

### AI æ¨¡å—ï¼ˆPythonï¼‰
- PyTorch 2.x + timm (ConvNeXt)
- Albumentations æ•°æ®å¢å¼º
- ONNX Runtime / TensorRT
- FastAPI / Flask

### åç«¯æœåŠ¡ï¼ˆJavaï¼Œå¾…å®ç°ï¼‰
- Spring Boot 3.2 + Spring Cloud
- Spring Cloud Gateway + Nacos
- PostgreSQL + Redis + MinIO
- RabbitMQ

### éƒ¨ç½²è¿ç»´
- Docker + Docker Compose
- Kubernetes
- GitLab CI/CD
- Prometheus + Grafana